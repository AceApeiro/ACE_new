<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>ACE – ANI XML Extractor (Single File)</title>

  <!-- PDF.js (no build / no npm) -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/4.10.38/pdf.min.js"></script>

  <style>
    :root{
      --bg:#0b1220; --panel:#101a2f; --panel2:#0f1730; --text:#e8eefc; --muted:#a8b4d6;
      --good:#2ecc71; --bad:#ff4d4d; --warn:#f1c40f; --info:#4da3ff; --line:#1e2b4f;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji", "Segoe UI Emoji";
    }
    body{ margin:0; background:linear-gradient(180deg,#070b14,#0b1220 50%,#070b14); color:var(--text); font-family:var(--sans);}
    header{ padding:18px 16px; border-bottom:1px solid var(--line); background:rgba(16,26,47,.65); backdrop-filter: blur(8px); position:sticky; top:0; z-index:10;}
    header h1{ margin:0; font-size:18px; letter-spacing:.2px;}
    header .sub{ color:var(--muted); font-size:12px; margin-top:6px; }
    .wrap{ display:grid; grid-template-columns: 360px 1fr 420px; gap:12px; padding:12px; }
    .card{ background:rgba(16,26,47,.72); border:1px solid var(--line); border-radius:14px; overflow:hidden; box-shadow: 0 10px 30px rgba(0,0,0,.25); }
    .card .hd{ padding:12px 12px 10px; border-bottom:1px solid var(--line); background:rgba(15,23,48,.7); }
    .card .hd .t{ font-weight:700; font-size:13px; }
    .card .bd{ padding:12px; }
    .row{ display:flex; gap:8px; align-items:center; flex-wrap:wrap;}
    .btn{
      cursor:pointer; border:1px solid var(--line); background:#0f1730; color:var(--text);
      padding:8px 10px; border-radius:10px; font-size:12px;
    }
    .btn:hover{ border-color:#2a3a66; }
    .btn.primary{ background:#123058; border-color:#294a85; }
    .btn.danger{ background:#3a0f1a; border-color:#6b1a2d; }
    .btn.small{ padding:6px 8px; font-size:11px; border-radius:9px; }

    input[type="file"]{ width:100%; }
    textarea{
      width:100%; min-height:120px; resize:vertical; border-radius:12px;
      border:1px solid var(--line); background:#0b1329; color:var(--text); padding:10px;
      font-family:var(--mono); font-size:11px; line-height:1.35;
    }
    .kv{ display:grid; grid-template-columns: 160px 1fr; gap:8px; margin-top:8px; }
    .k{ color:var(--muted); font-size:12px; padding-top:2px;}
    .v{ font-family:var(--mono); font-size:12px; white-space:pre-wrap; word-break:break-word;}
    .badge{
      display:inline-flex; align-items:center; gap:6px;
      padding:4px 9px; border-radius:999px; font-size:11px; border:1px solid var(--line);
      background:rgba(0,0,0,.15);
    }
    .dot{ width:8px; height:8px; border-radius:99px; display:inline-block; }
    .good .dot{ background:var(--good); } .bad .dot{ background:var(--bad); }
    .warn .dot{ background:var(--warn); } .info .dot{ background:var(--info); }

    .hr{ height:1px; background:var(--line); margin:10px 0; }
    .mono{ font-family:var(--mono); }

    .twoCol{ display:grid; grid-template-columns:1fr 1fr; gap:10px; }
    .mini{ font-size:11px; color:var(--muted); }

    pre{
      margin:0; padding:10px; border-radius:12px;
      border:1px solid var(--line); background:#071025; color:var(--text);
      overflow:auto; font-family:var(--mono); font-size:11px; line-height:1.35;
    }
    .footerNote{ color:var(--muted); font-size:11px; margin-top:10px;}
    @media (max-width: 1200px){
      .wrap{ grid-template-columns: 1fr; }
    }
  </style>
</head>

<body>
<header>
  <h1>ACE – ANI XML Extractor (Single File / GitHub Pages)</h1>
  <div class="sub">Strict gating like Excel conditional formatting: PDF vs HTML vs Scrape. If HOLD → no XML. If OK → outputs Elsevier ANI XML structure.</div>
</header>

<div class="wrap">

  <!-- LEFT: Uploads -->
  <section class="card">
    <div class="hd"><div class="t">1) Upload Support Docs</div></div>
    <div class="bd">

      <div class="mini">PDF (required)</div>
      <input id="pdfFile" type="file" accept="application/pdf" />
      <div class="hr"></div>

      <div class="mini">HTML Summary (arXiv abstract page saved as .html OR pasted text)</div>
      <input id="htmlFile" type="file" accept=".html,.htm,text/html,text/plain" />
      <textarea id="htmlPaste" placeholder="Optional: paste HTML summary text here (if you didn’t upload a file)"></textarea>

      <div class="hr"></div>

      <div class="mini">Scrape/Metadata (text/html/xml/json – anything, we’ll try parse arXiv id/version)</div>
      <input id="scrapeFile" type="file" accept=".txt,.json,.xml,.html,.htm,text/plain,application/json,text/xml,application/xml,text/html" />
      <textarea id="scrapePaste" placeholder="Optional: paste scrape/metadata text here"></textarea>

      <div class="hr"></div>

      <div class="row">
        <button class="btn primary" id="runBtn">Run Validation + Extract</button>
        <button class="btn" id="resetBtn">Reset</button>
      </div>

      <div class="footerNote">
        Notes:
        <ul>
          <li>HTML rule: use <b>Cite as</b> → <b>second line</b> for ID+version.</li>
          <li>Affiliations/emails: we scan first 2 pages + last 2 pages (since some appear at end).</li>
          <li>References: best-effort from “References” section in PDF.</li>
        </ul>
      </div>
    </div>
  </section>

  <!-- CENTER: Gating + extracted fields -->
  <section class="card">
    <div class="hd"><div class="t">2) Conditional Logic Results (STRICT)</div></div>
    <div class="bd">

      <div class="twoCol">
        <div>
          <div class="mini">PDF detected</div>
          <div id="pdfBadge"></div>
          <div class="kv">
            <div class="k">PDF arXiv ID</div><div class="v" id="pdfId">—</div>
            <div class="k">PDF Version</div><div class="v" id="pdfVer">—</div>
            <div class="k">PDF Title (guess)</div><div class="v" id="pdfTitle">—</div>
          </div>
        </div>
        <div>
          <div class="mini">HTML + Scrape detected</div>
          <div id="hsBadge"></div>
          <div class="kv">
            <div class="k">HTML ID</div><div class="v" id="htmlId">—</div>
            <div class="k">HTML Version</div><div class="v" id="htmlVer">—</div>
            <div class="k">Scrape ID</div><div class="v" id="scId">—</div>
            <div class="k">Scrape Version</div><div class="v" id="scVer">—</div>
          </div>
        </div>
      </div>

      <div class="hr"></div>

      <div class="mini">TITLE comparison (PDF vs HTML)</div>
      <div id="titleBadge"></div>
      <div class="kv">
        <div class="k">Chosen Title</div><div class="v" id="chosenTitle">—</div>
      </div>

      <div class="hr"></div>

      <div class="mini">FINAL Gate</div>
      <div id="finalBadge"></div>
      <div class="kv">
        <div class="k">Hold reason</div><div class="v" id="holdReason">—</div>
      </div>

      <div class="hr"></div>

      <div class="mini">Extracted payload (only meaningful if PASS)</div>
      <div class="kv">
        <div class="k">Keywords</div><div class="v" id="kwOut">—</div>
        <div class="k">Abstract</div><div class="v" id="absOut">—</div>
        <div class="k">Authors</div><div class="v" id="authOut">—</div>
        <div class="k">Affiliations</div><div class="v" id="affOut">—</div>
        <div class="k">Emails</div><div class="v" id="emailOut">—</div>
        <div class="k">References (count)</div><div class="v" id="refCount">—</div>
      </div>

    </div>
  </section>

  <!-- RIGHT: XML output -->
  <section class="card">
    <div class="hd"><div class="t">3) Final ANI XML Output</div></div>
    <div class="bd">
      <div class="row">
        <button class="btn small" id="copyXmlBtn">Copy XML</button>
        <button class="btn small" id="downloadXmlBtn">Download XML</button>
      </div>
      <div class="hr"></div>
      <pre id="xmlOut">&lt;!-- XML will appear here if PASS --&gt;</pre>
    </div>
  </section>

</div>

<script>
/* =========================
   Small UI helpers
========================= */
function badge(text, kind){
  const cls = kind || "info";
  return `<span class="badge ${cls}"><span class="dot"></span><span>${escapeHtml(text)}</span></span>`;
}
function escapeHtml(s){
  return String(s ?? "").replace(/[&<>"']/g, m => ({'&':'&amp;','<':'&lt;','>':'&gt;','"':'&quot;',"'":'&#39;'}[m]));
}
function setEl(id, value){ document.getElementById(id).textContent = value ?? "—"; }
function setHtml(id, html){ document.getElementById(id).innerHTML = html; }

/* =========================
   Text normalization
   (We need strict comparisons)
========================= */

// STRICT: preserve punctuation/hyphens (per your rule)
// But remove formatting wrappers in HTML like $...$ around words (used for italics/bold sometimes)
function normalizeTitleForCompare(s){
  s = (s||"").trim();
  // remove "Preprint" + trailing asterisks used in some PDFs/HTMLs
  s = s.replace(/\bPreprint\b/gi, "").replace(/\*+$/g,"").trim();
  // remove superscript markers that are not part of content (best effort)
  s = s.replace(/^\s*[\u00B9\u00B2\u00B3\u2070-\u2079]+\s*/g, "");
  // remove $ wrappers that are just formatting: $z > 6$ (keep inner)
  s = s.replace(/\$([^$]+)\$/g, "$1");
  // collapse multiple spaces
  s = s.replace(/[ \t]+/g," ").trim();
  return s;
}

// VERY strict equality (after the minimal normalization above)
function titlesExactlySame(pdfTitle, htmlTitle){
  const a = normalizeTitleForCompare(pdfTitle);
  const b = normalizeTitleForCompare(htmlTitle);
  return a === b;
}

// If totally different (not just extra words), choose HTML. Otherwise choose the more complete (longer) one.
function chooseTitle(pdfTitle, htmlTitle){
  const a = normalizeTitleForCompare(pdfTitle);
  const b = normalizeTitleForCompare(htmlTitle);

  if (!a && b) return b;
  if (!b && a) return a;
  if (!a && !b) return "";

  // Token overlap check to decide "totally different"
  const ta = new Set(a.toLowerCase().split(/\s+/).filter(Boolean));
  const tb = new Set(b.toLowerCase().split(/\s+/).filter(Boolean));
  const common = [...ta].filter(x => tb.has(x)).length;
  const overlap = common / Math.max(1, Math.min(ta.size, tb.size));

  // If overlap is very low => totally different => HTML
  if (overlap < 0.35) return b;

  // else pick more complete
  return (b.length > a.length) ? b : a;
}

/* =========================
   arXiv ID extraction
========================= */

// returns {id:"2409.09977", ver:"v2"} or {id:"2409.09977", ver:""} or null
function parseArxivIdVersion(raw){
  if (!raw) return null;
  let s = String(raw);

  // remove brackets wrappers like (arXiv:...) or [arXiv:...]
  s = s.replace(/[()\[\]]/g," ");

  // common forms:
  // arXiv:2409.09977v2
  // 2409.09977v2
  // arXiv:2409.09977
  // 2409.09977
  // also old-style like hep-th/9901001v1 (rare) -> handle too
  const reNew = /(?:arxiv\s*:?\s*)?(\d{4}\.\d{4,5})(v\d+)?/i;
  const reOld = /(?:arxiv\s*:?\s*)?([a-z\-]+\/\d{7})(v\d+)?/i;

  let m = s.match(reNew);
  if (m) return { id: m[1], ver: m[2] || "" };

  m = s.match(reOld);
  if (m) return { id: m[1], ver: m[2] || "" };

  return null;
}

// HTML rule: find "Cite as:" then use the SECOND LINE after it.
function extractArxivFromHtmlCiteAs(htmlText){
  const t = (htmlText||"");
  const idx = t.toLowerCase().indexOf("cite as");
  if (idx === -1) return null;

  const tail = t.slice(idx, idx + 1000); // enough window
  // Split into lines (keep simple)
  const lines = tail.replace(/\r/g,"").split("\n").map(x => x.trim()).filter(Boolean);

  // Find the line that contains "Cite as"
  const citeLineIndex = lines.findIndex(l => /cite\s+as/i.test(l));
  if (citeLineIndex === -1) return null;

  // second line after it (your instruction)
  const second = lines[citeLineIndex + 2] || "";
  // but sometimes HTML has "Cite as:" then immediately an id line; in that case fallback to next lines
  const candidates = [
    second,
    lines[citeLineIndex + 1] || "",
    lines[citeLineIndex + 3] || "",
    tail
  ];

  for (const c of candidates){
    const parsed = parseArxivIdVersion(c);
    if (parsed && parsed.id) return parsed;
  }
  return null;
}

// Generic: find first arXiv id match anywhere
function extractArxivGeneric(text){
  const parsed = parseArxivIdVersion(text);
  if (parsed) return parsed;

  // as fallback, scan for all matches and pick the first
  const t = (text||"");
  const all = t.match(/(?:arXiv:)?\d{4}\.\d{4,5}v?\d*/gi);
  if (all && all.length){
    return parseArxivIdVersion(all[0]);
  }
  return null;
}

/* =========================
   PDF extraction using PDF.js
========================= */
pdfjsLib.GlobalWorkerOptions.workerSrc =
  "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/4.10.38/pdf.worker.min.js";

async function readFileAsText(file){
  if (!file) return "";
  return await file.text();
}
async function readPdfText(file){
  const buf = await file.arrayBuffer();
  const pdf = await pdfjsLib.getDocument({ data: buf }).promise;
  const n = pdf.numPages;

  // first 2 pages + last 2 pages (for affiliations/emails at end)
  const pages = new Set([1,2,n-1,n].filter(p => p >= 1 && p <= n));
  let out = [];
  for (const p of [...pages]){
    const page = await pdf.getPage(p);
    const tc = await page.getTextContent();
    const txt = tc.items.map(it => it.str).join(" ");
    out.push(`\n\n--- PAGE ${p} ---\n` + txt);
  }
  return out.join("\n");
}

// Guess title: take the earliest long-ish line before "Abstract"
function guessPdfTitleFromText(pdfText){
  const t = (pdfText||"").replace(/\s+/g," ").trim();
  if (!t) return "";
  const absIdx = t.toLowerCase().indexOf(" abstract ");
  const head = (absIdx > 0 ? t.slice(0, absIdx) : t.slice(0, 2200));

  // Split into segments by "PAGE" markers and use first page chunk
  const firstChunk = head.split("--- PAGE").slice(0,2).join(" ");

  // Heuristic: find the longest "sentence-like" fragment early
  // We avoid picking “arXiv:....”
  const candidates = firstChunk.split(/ {2,}|\s{3,}| \u00B7 /g)
    .map(s => s.trim())
    .filter(s => s.length >= 12)
    .filter(s => !/arxiv:/i.test(s))
    .filter(s => !/^\d{4}\.\d{4,5}/.test(s));

  candidates.sort((a,b)=> b.length - a.length);
  return candidates[0] || "";
}

// Extract authors, affiliations, emails from PDF text (best effort)
function extractEmails(text){
  const t = text||"";
  const emails = [...new Set((t.match(/[a-z0-9._%+\-]+@[a-z0-9.\-]+\.[a-z]{2,}/gi) || []).map(e=>e.trim()))];
  return emails;
}

// Try parse affiliation lines like: "1 Dept..., 2 School..."
function extractAffiliations(text){
  const lines = (text||"").replace(/\r/g,"").split("\n").map(l=>l.trim()).filter(Boolean);

  // Pull lines around where affiliations usually appear: near "PAGE 1" and near end pages too
  const joined = lines.join("\n");

  // Find blocks that contain patterns like "1 Dept" or "2 School" etc.
  const affs = [];
  const re = /(^|\n)\s*([1-9]\d?)\s*([A-Z][^\n]{8,})/g;
  let m;
  while ((m = re.exec(joined)) !== null){
    const idx = m[2];
    const val = m[3].trim();
    // avoid capturing headings or random “1 Introduction”
    if (/^introduction\b/i.test(val)) continue;
    if (val.length < 12) continue;
    affs.push({ idx, text: val });
  }

  // De-dup by idx+text
  const seen = new Set();
  const clean = [];
  for (const a of affs){
    const key = a.idx + "||" + a.text;
    if (seen.has(key)) continue;
    seen.add(key);
    clean.push(a);
  }

  // If none found, fallback: return empty
  return clean;
}

// Authors are hard from raw PDF text; we’ll attempt:
// - find sequence of names near start (before Abstract)
// - split by commas
function extractAuthors(text){
  const t = (text||"").replace(/\s+/g," ").trim();
  if (!t) return [];

  const absIdx = t.toLowerCase().indexOf(" abstract ");
  const head = (absIdx > 0 ? t.slice(0, absIdx) : t.slice(0, 1800));

  // Remove title guess part by cutting after first long chunk
  // Then find likely author list: multiple capitalized words separated by commas
  const maybe = head
    .replace(/arxiv:\s*\S+/gi,"")
    .replace(/\bpreprint\b/gi,"")
    .replace(/\s{2,}/g," ")
    .trim();

  // Find best comma-separated capitalized list
  const chunks = maybe.split(/(?:\bby\b|\n|--- PAGE 1 ---)/i);
  let best = "";
  for (const c of chunks){
    if ((c.match(/,/g)||[]).length >= 1 && c.length > best.length) best = c;
  }

  // parse names
  const rawNames = best.split(",")
    .map(x=>x.trim())
    .filter(x=>x.length >= 4)
    .filter(x=>/^[A-Z][A-Za-z.\-’' ]+$/.test(x));

  // de-dup
  const out = [];
  const seen = new Set();
  for (const n of rawNames){
    const k = n.toLowerCase();
    if (seen.has(k)) continue;
    seen.add(k);
    out.push(n);
  }
  return out.slice(0, 30);
}

/* =========================
   Keywords + Abstract extraction
========================= */
function extractKeywords(text){
  const t = (text||"");
  // headings: Keywords / Index Terms / Keywords and Phrases / Subject Headings
  const re = /(keywords|index terms|keywords and phrases|subject headings)\s*[:\-]?\s*/ig;
  const m = re.exec(t);
  if (!m) return [];
  const start = m.index + m[0].length;
  const window = t.slice(start, start + 400);

  // stop at Abstract or Introduction etc
  const stopIdx = window.search(/\b(abstract|introduction|1\s+introduction)\b/i);
  const block = (stopIdx >= 0 ? window.slice(0, stopIdx) : window);

  // Split by separators (not spaces)
  const parts = block.split(/[;•\u2022|,·—–\-•]/g).map(s=>s.trim()).filter(Boolean);

  // clean headings accidentally included
  const clean = parts
    .map(p=>p.replace(/^\b(keyword|keywords|index terms)\b[:\-]?\s*/i,"").trim())
    .filter(p=>p.length >= 2);

  // de-dup
  return [...new Set(clean)].slice(0, 40);
}

function extractAbstract(text){
  const t = (text||"");
  // abstract titles: Abstract / Summary / Synopsis / Summary and Conclusions
  const re = /\b(abstract|summary|synopsis|summary and conclusions)\b\s*[:\-]?\s*/i;
  const m = t.match(re);
  if (!m) return "";
  const idx = t.toLowerCase().indexOf(m[0].toLowerCase());
  const tail = t.slice(idx + m[0].length);

  // stop at "1 Introduction" or "Introduction" or "Keywords" etc (best effort)
  const stop = tail.search(/\b(1\s+introduction|introduction|keywords|index terms|references)\b/i);
  let abs = (stop >= 0 ? tail.slice(0, stop) : tail.slice(0, 3000));

  abs = abs.replace(/\s+/g," ").trim();

  // Replace very complex equations? (best-effort placeholder only if massive math density)
  const mathHits = (abs.match(/[=<>\\^_{}]/g) || []).length;
  if (mathHits > 80) abs = abs.replace(/\$[^$]+\$/g, "(Formula presented)");

  return abs;
}

/* =========================
   References extraction (best effort)
========================= */
function extractReferences(pdfText){
  const t = (pdfText||"");
  const lower = t.toLowerCase();
  let idx = lower.indexOf(" references ");
  if (idx < 0) idx = lower.indexOf("\nreferences\n");
  if (idx < 0) return [];

  const tail = t.slice(idx + 10);
  // Split into lines, keep non-empty
  const lines = tail.replace(/\r/g,"").split("\n").map(l=>l.trim()).filter(Boolean);

  // Collect lines until we hit appendices or end markers
  const stopWords = /(appendix|supplementary|acknowledg|about the authors)/i;
  const collected = [];
  for (const l of lines){
    if (stopWords.test(l)) break;
    if (l.length < 2) continue;
    // ignore page markers
    if (/--- PAGE \d+ ---/i.test(l)) continue;
    collected.push(l);
  }

  // Group into references by numbered patterns
  const refs = [];
  let buf = "";
  for (const l of collected){
    const isNew = /^\[?\d{1,3}\]?\s+/.test(l) || /^\d{1,3}\.\s+/.test(l);
    if (isNew && buf){
      refs.push(buf.trim());
      buf = l;
    } else {
      buf += (buf ? " " : "") + l;
    }
  }
  if (buf) refs.push(buf.trim());

  // Clean numbering prefix
  return refs.map(r => r.replace(/^\[?\d{1,3}\]?\s+/, "").replace(/^\d{1,3}\.\s+/, "").trim())
             .filter(Boolean)
             .slice(0, 500);
}

/* =========================
   ANI XML builder (structure matches your sample)
========================= */
function buildAniXml(payload){
  const ts = new Date().toISOString();

  const nsAni = "http://www.elsevier.com/xml/ani/ani";
  const nsCe  = "http://www.elsevier.com/xml/ani/common";

  const {
    arxivFull, title, keywords, abstractText,
    authors, affiliations, emails, references
  } = payload;

  const kwXml = (keywords||[]).map(k => `      <author-keyword>${xmlEsc(k)}</author-keyword>`).join("\n");

  const authorGroupsXml = (authors||[]).map((name, i) => {
    const seq = i + 1;
    const parsed = splitName(name);
    const email = (emails||[])[i] || ""; // best effort mapping

    // For affiliations: if we have numbered affiliations, put full source-text line
    // (Better than dumping the whole page text like your broken output)
    const affText = buildAffSourceText(affiliations, emails);

    return `    <author-group seq="${seq}">
      <author seq="${seq}">
        <ce:initials>${xmlEsc(parsed.initials || "")}</ce:initials>
        <ce:surname>${xmlEsc(parsed.surname || "")}</ce:surname>
        <ce:given-name>${xmlEsc(parsed.given || "")}</ce:given-name>${email ? `\n        <ce:e-address>${xmlEsc(email)}</ce:e-address>` : ""}
      </author>
      <affiliation>
        <ce:source-text>${xmlEsc(affText || "")}</ce:source-text>
      </affiliation>
    </author-group>`;
  }).join("\n");

  const refsXml = (references||[]).map((r, i) => {
    const seq = i + 1;
    return `      <reference seq="${seq}">
        <ref-info/>
        <ref-fulltext>${xmlEsc(r)}</ref-fulltext>
        <ce:source-text>${xmlEsc(r)}</ce:source-text>
      </reference>`;
  }).join("\n");

  return `<?xml version="1.0" encoding="UTF-8"?>
<units xmlns="${nsAni}" xmlns:ce="${nsCe}">
  <unit type="ARTICLE">
    <unit-info>
      <unit-id>1</unit-id>
      <order-id>unknown</order-id>
      <parcel-id>none</parcel-id>
      <supplier-id>4</supplier-id>
      <timestamp>${ts}</timestamp>
    </unit-info>
    <unit-content>
      <bibrecord>
        <item-info>
          <status state="new"/>
          <itemidlist>
            <itemid idtype="ARXIV">${xmlEsc(arxivFull || "")}</itemid>
          </itemidlist>
        </item-info>
        <head>
          <citation-info>
            <citation-type code="ar"/>
            <citation-language xml:lang="ENG"/>
            <abstract-language xml:lang="ENG"/>
${keywords && keywords.length ? `            <author-keywords>\n${kwXml}\n            </author-keywords>` : ""}
          </citation-info>
          <citation-title>
            <titletext xml:lang="ENG" original="y">${xmlEsc(title || "")}</titletext>
          </citation-title>
${authorGroupsXml ? authorGroupsXml : ""}
          <abstracts>
            <abstract original="y" xml:lang="ENG">
              <ce:para>${xmlEsc(abstractText || "")}</ce:para>
            </abstract>
          </abstracts>
          <source srcid="???"/>
        </head>
        <tail>
          <bibliography refcount="${(references||[]).length}">
${refsXml}
          </bibliography>
        </tail>
      </bibrecord>
    </unit-content>
  </unit>
</units>`;
}

function xmlEsc(s){
  return String(s ?? "")
    .replace(/&/g,"&amp;")
    .replace(/</g,"&lt;")
    .replace(/>/g,"&gt;")
    .replace(/"/g,"&quot;")
    .replace(/'/g,"&apos;");
}

function splitName(full){
  // basic: last token = surname, rest = given
  const parts = (full||"").trim().split(/\s+/).filter(Boolean);
  if (!parts.length) return { given:"", surname:"", initials:"" };
  const surname = parts[parts.length-1];
  const given = parts.slice(0,-1).join(" ");
  const initials = parts.slice(0,-1).map(p => (p[0] ? (p[0].toUpperCase()+".") : "")).join(" ");
  return { given, surname, initials };
}

function buildAffSourceText(affs, emails){
  if (affs && affs.length){
    // Format:
    // 1Dept..., 2School...
    // 1email, 2email...
    const affLines = affs.map(a => `${a.idx}${a.text}`);
    const emailLines = (emails||[]).length
      ? (emails.map((e,i)=> `${i+1}${e}`).join(", "))
      : "";
    return (affLines.join(" | ") + (emailLines ? ` | ${emailLines}` : "")).trim();
  }
  return "";
}

/* =========================
   STRICT VALIDATION (your rules)
========================= */
function validateSupportDocs(pdf, html, sc, pdfTitle, htmlTitle){
  // pdf/html/sc are {id,ver} or null
  // Rule set (exactly as you described):
  //
  // If PDF HAS ID:
  //   - if PDF has version: PDF/HTML/SCRAPE must match BOTH id and version
  //   - if PDF has NO version: PDF id must match HTML+SCRAPE id AND HTML+SCRAPE versions must match each other
  //
  // If PDF has NO ID:
  //   - Titles must match EXACT (strict). If not -> HOLD
  //   - If titles match -> HTML+SCRAPE id+version must match each other. If not -> HOLD
  //
  const pdfHasId = !!(pdf && pdf.id);
  const htmlHasId = !!(html && html.id);
  const scHasId = !!(sc && sc.id);

  const pdfId = pdf?.id || "";
  const pdfVer = pdf?.ver || "";
  const htmlId = html?.id || "";
  const htmlVer = html?.ver || "";
  const scId = sc?.id || "";
  const scVer = sc?.ver || "";

  // If missing HTML or scrape id we HOLD because cannot validate
  if (!htmlHasId || !scHasId){
    return { ok:false, reason:`Missing ID: HTML has=${htmlHasId}, Scrape has=${scHasId}` };
  }

  if (pdfHasId){
    // PDF ID must match both HTML and SCRAPE IDs always
    if (pdfId !== htmlId || pdfId !== scId){
      return { ok:false, reason:`ID mismatched: PDF=${pdfId}${pdfVer}, HTML=${htmlId}${htmlVer}, SCRAPE=${scId}${scVer}` };
    }

    // PDF has version?
    if (pdfVer){
      // all versions must match exactly
      if (pdfVer !== htmlVer || pdfVer !== scVer){
        return { ok:false, reason:`Version mismatched: PDF=${pdfId}${pdfVer}, HTML=${htmlId}${htmlVer}, SCRAPE=${scId}${scVer}` };
      }
      return { ok:true, reason:"OK (PDF id+version match)" };
    } else {
      // PDF no version: HTML & SCRAPE versions must match each other
      if (htmlVer !== scVer){
        return { ok:false, reason:`Version mismatched (PDF has no version): HTML=${htmlId}${htmlVer}, SCRAPE=${scId}${scVer}` };
      }
      return { ok:true, reason:"OK (PDF id match, HTML+SCRAPE versions match)" };
    }
  } else {
    // PDF has NO ID
    const titleSame = titlesExactlySame(pdfTitle, htmlTitle);
    if (!titleSame){
      return { ok:false, reason:"PDF has no ID and titles mismatch (strict) → HOLD" };
    }
    // titles match -> html+scrape must match id+ver
    if (htmlId !== scId || htmlVer !== scVer){
      return { ok:false, reason:`Version/ID mismatched (PDF no id): HTML=${htmlId}${htmlVer}, SCRAPE=${scId}${scVer}` };
    }
    return { ok:true, reason:"OK (PDF no id; titles match; HTML+SCRAPE match)" };
  }
}

/* =========================
   Main runner
========================= */
const elPdf = document.getElementById("pdfFile");
const elHtmlFile = document.getElementById("htmlFile");
const elHtmlPaste = document.getElementById("htmlPaste");
const elScFile = document.getElementById("scrapeFile");
const elScPaste = document.getElementById("scrapePaste");
const runBtn = document.getElementById("runBtn");

let lastXml = "";

document.getElementById("resetBtn").addEventListener("click", () => {
  elPdf.value = "";
  elHtmlFile.value = "";
  elHtmlPaste.value = "";
  elScFile.value = "";
  elScPaste.value = "";
  setHtml("pdfBadge","");
  setHtml("hsBadge","");
  setHtml("titleBadge","");
  setHtml("finalBadge","");
  setEl("pdfId","—"); setEl("pdfVer","—"); setEl("pdfTitle","—");
  setEl("htmlId","—"); setEl("htmlVer","—");
  setEl("scId","—"); setEl("scVer","—");
  setEl("chosenTitle","—");
  setEl("holdReason","—");
  setEl("kwOut","—");
  setEl("absOut","—");
  setEl("authOut","—");
  setEl("affOut","—");
  setEl("emailOut","—");
  setEl("refCount","—");
  document.getElementById("xmlOut").textContent = "<!-- XML will appear here if PASS -->";
  lastXml = "";
});

runBtn.addEventListener("click", async () => {
  try{
    const pdfFile = elPdf.files?.[0];
    if (!pdfFile){
      alert("PDF is required.");
      return;
    }

    // read html text
    const htmlFile = elHtmlFile.files?.[0];
    const htmlTextFromFile = htmlFile ? await readFileAsText(htmlFile) : "";
    const htmlText = (elHtmlPaste.value || htmlTextFromFile || "").trim();

    // read scrape text
    const scFile = elScFile.files?.[0];
    const scTextFromFile = scFile ? await readFileAsText(scFile) : "";
    const scText = (elScPaste.value || scTextFromFile || "").trim();

    // PDF text
    setHtml("pdfBadge", badge("Reading PDF…", "info"));
    const pdfText = await readPdfText(pdfFile);
    setHtml("pdfBadge", badge("PDF read OK", "good"));

    // PDF ID/version from PDF text (arXiv line)
    // (We take first match; if multiple, prefer one containing "arXiv:")
    const pdfParsed = (() => {
      const hit = (pdfText.match(/arXiv:\s*[^\s]+/i) || [])[0];
      return parseArxivIdVersion(hit || pdfText) || null;
    })();

    // HTML ID/version: strict rule: cite as second line
    const htmlParsed = extractArxivFromHtmlCiteAs(htmlText) || extractArxivGeneric(htmlText);

    // Scrape ID/version: generic scan
    const scParsed = extractArxivGeneric(scText);

    // Title: HTML title from <title> or h1, and PDF title guess
    const pdfTitleGuess = guessPdfTitleFromText(pdfText);
    const htmlTitle = (() => {
      if (!htmlText) return "";
      // try <title>
      const m1 = htmlText.match(/<title[^>]*>([\s\S]*?)<\/title>/i);
      if (m1) return m1[1].replace(/\s+/g," ").trim();
      // try h1
      const m2 = htmlText.match(/<h1[^>]*>([\s\S]*?)<\/h1>/i);
      if (m2) return m2[1].replace(/<[^>]+>/g," ").replace(/\s+/g," ").trim();
      return "";
    })();

    // UI populate
    setEl("pdfId", pdfParsed?.id ? pdfParsed.id : "");
    setEl("pdfVer", pdfParsed?.ver ? pdfParsed.ver : "");
    setEl("pdfTitle", pdfTitleGuess || "");

    setEl("htmlId", htmlParsed?.id ? htmlParsed.id : "");
    setEl("htmlVer", htmlParsed?.ver ? htmlParsed.ver : "");
    setEl("scId", scParsed?.id ? scParsed.id : "");
    setEl("scVer", scParsed?.ver ? scParsed.ver : "");

    setHtml("hsBadge", (htmlParsed?.id && scParsed?.id) ? badge("HTML+Scrape read OK", "good") : badge("Missing HTML/Scrape IDs", "bad"));

    // Title comparison badge
    const same = titlesExactlySame(pdfTitleGuess, htmlTitle);
    setHtml("titleBadge", same ? badge("OK – same (strict)", "good") : badge("Mismatch (stricts) – may still be OK if PDF has ID", "warn"));

    // Validate (STRICT)
    const gate = validateSupportDocs(pdfParsed, htmlParsed, scParsed, pdfTitleGuess, htmlTitle);

    // Decide chosen title per your rule
    const chosenTitle = chooseTitle(pdfTitleGuess, htmlTitle);
    setEl("chosenTitle", chosenTitle);

    // If HOLD: show reason, no XML
    if (!gate.ok){
      setHtml("finalBadge", badge("HOLD – DO NOT PROCESS", "bad"));
      setEl("holdReason", gate.reason);

      setEl("kwOut","—");
      setEl("absOut","—");
      setEl("authOut","—");
      setEl("affOut","—");
      setEl("emailOut","—");
      setEl("refCount","—");
      document.getElementById("xmlOut").textContent = "<!-- HOLD: no XML generated -->";
      lastXml = "";
      return;
    }

    setHtml("finalBadge", badge("OK – PROCESS", "good"));
    setEl("holdReason", gate.reason);

    // Extract payload
    const keywords = extractKeywords(pdfText);
    const abstractText = extractAbstract(pdfText);
    const emails = extractEmails(pdfText);
    const affiliations = extractAffiliations(pdfText);
    const authors = extractAuthors(pdfText);
    const references = extractReferences(pdfText);

    setEl("kwOut", keywords.length ? keywords.join(" | ") : "");
    setEl("absOut", abstractText || "");
    setEl("authOut", authors.length ? authors.join(" | ") : "");
    setEl("affOut", affiliations.length ? affiliations.map(a => `${a.idx}${a.text}`).join(" | ") : "");
    setEl("emailOut", emails.length ? emails.join(" | ") : "");
    setEl("refCount", String(references.length));

    // Compose arXiv full for XML: prefer HTML/SCRAPE (they’re validated), include version if present
    const arxivFull = (htmlParsed?.id || "") + (htmlParsed?.ver || "");

    const xml = buildAniXml({
      arxivFull,
      title: chosenTitle,
      keywords,
      abstractText,
      authors,
      affiliations,
      emails,
      references
    });

    lastXml = xml;
    document.getElementById("xmlOut").textContent = xml;

  } catch(err){
    console.error(err);
    alert("Error: " + (err?.message || err));
  }
});

/* =========================
   Copy / Download XML
========================= */
document.getElementById("copyXmlBtn").addEventListener("click", async () => {
  if (!lastXml){ alert("No XML to copy (HOLD or not run)."); return; }
  await navigator.clipboard.writeText(lastXml);
  alert("XML copied.");
});

document.getElementById("downloadXmlBtn").addEventListener("click", () => {
  if (!lastXml){ alert("No XML to download (HOLD or not run)."); return; }
  const blob = new Blob([lastXml], { type:"application/xml" });
  const url = URL.createObjectURL(blob);
  const a = document.createElement("a");
  a.href = url;
  a.download = "ace_output.xml";
  a.click();
  URL.revokeObjectURL(url);
});
</script>
</body>
</html>
