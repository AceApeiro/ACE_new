<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1.0" />
  <title>ACE – ANI XML Extractor (Single File)</title>

  <!-- PDF.js (CDN) -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/4.6.82/pdf.min.js"></script>
  <script>
    // pdf.js worker
    window.pdfjsLib.GlobalWorkerOptions.workerSrc =
      "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/4.6.82/pdf.worker.min.js";
  </script>

  <style>
    :root {
      --bg: #0b0f14;
      --panel: #0f1620;
      --panel2: #111c28;
      --text: #e6eef8;
      --muted: #9fb2c7;
      --accent: #40c4ff;
      --good: #3ddc97;
      --warn: #ffcc66;
      --bad: #ff5c77;
      --border: rgba(255,255,255,.08);
      --shadow: 0 12px 40px rgba(0,0,0,.35);
    }
    * { box-sizing: border-box; }
    body {
      margin: 0;
      background: radial-gradient(1200px 800px at 20% -10%, rgba(64,196,255,.12), transparent 60%),
                  radial-gradient(900px 600px at 95% 10%, rgba(61,220,151,.10), transparent 55%),
                  var(--bg);
      color: var(--text);
      font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif;
    }
    header {
      position: sticky;
      top: 0;
      z-index: 9;
      background: rgba(11,15,20,.85);
      backdrop-filter: blur(10px);
      border-bottom: 1px solid var(--border);
      padding: 14px 18px;
      display: flex;
      gap: 10px;
      align-items: center;
      justify-content: space-between;
    }
    header h1 {
      margin: 0;
      font-size: 16px;
      font-weight: 700;
      letter-spacing: .2px;
    }
    header .sub {
      color: var(--muted);
      font-size: 12px;
      margin-top: 2px;
    }
    header .left { display:flex; flex-direction:column; }
    header .right { display:flex; gap:10px; align-items:center; flex-wrap:wrap; }

    button {
      background: linear-gradient(180deg, rgba(64,196,255,.22), rgba(64,196,255,.08));
      color: var(--text);
      border: 1px solid rgba(64,196,255,.35);
      padding: 10px 12px;
      border-radius: 12px;
      cursor: pointer;
      box-shadow: var(--shadow);
      font-weight: 600;
      font-size: 13px;
    }
    button:disabled {
      opacity: .45;
      cursor: not-allowed;
      box-shadow: none;
    }
    button.secondary {
      background: rgba(255,255,255,.05);
      border: 1px solid var(--border);
      box-shadow: none;
    }
    .container {
      display: grid;
      grid-template-columns: 370px 1fr 420px;
      gap: 14px;
      padding: 14px;
      align-items: start;
    }
    .card {
      background: linear-gradient(180deg, rgba(255,255,255,.06), rgba(255,255,255,.03));
      border: 1px solid var(--border);
      border-radius: 16px;
      box-shadow: var(--shadow);
      overflow: hidden;
    }
    .card .hd {
      padding: 12px 14px;
      border-bottom: 1px solid var(--border);
      background: rgba(255,255,255,.04);
      display:flex;
      justify-content: space-between;
      align-items:center;
      gap: 10px;
    }
    .card .hd h2 {
      margin: 0;
      font-size: 13px;
      letter-spacing: .2px;
    }
    .card .bd { padding: 12px 14px; }

    .field {
      margin-bottom: 10px;
    }
    .field label {
      display:block;
      color: var(--muted);
      font-size: 12px;
      margin-bottom: 6px;
    }
    input[type="file"], textarea, input[type="text"] {
      width: 100%;
      background: rgba(0,0,0,.22);
      border: 1px solid var(--border);
      color: var(--text);
      border-radius: 12px;
      padding: 10px 10px;
      font-size: 13px;
      outline: none;
    }
    textarea {
      min-height: 120px;
      resize: vertical;
      line-height: 1.35;
    }
    .pill {
      display:inline-flex;
      align-items:center;
      gap: 8px;
      padding: 8px 10px;
      border-radius: 999px;
      border: 1px solid var(--border);
      background: rgba(255,255,255,.04);
      color: var(--muted);
      font-size: 12px;
      margin-right: 8px;
      margin-bottom: 6px;
    }
    .pill strong { color: var(--text); font-weight: 700; }
    .ok { border-color: rgba(61,220,151,.35); color: rgba(61,220,151,.95); }
    .warn { border-color: rgba(255,204,102,.35); color: rgba(255,204,102,.95); }
    .bad { border-color: rgba(255,92,119,.35); color: rgba(255,92,119,.95); }

    .grid2 { display:grid; grid-template-columns: 1fr 1fr; gap: 10px; }
    .small { font-size: 12px; color: var(--muted); }
    .mono { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", monospace; }

    .pdfWrap {
      background: rgba(0,0,0,.18);
      border: 1px solid var(--border);
      border-radius: 16px;
      padding: 10px;
      min-height: 560px;
    }
    canvas { width: 100%; height: auto; display:block; border-radius: 12px; }
    .row { display:flex; gap: 10px; flex-wrap:wrap; align-items:center; }
    .sp { height: 10px; }

    .statusBox {
      padding: 12px;
      border-radius: 14px;
      border: 1px solid var(--border);
      background: rgba(0,0,0,.16);
    }
    .statusBox .title {
      font-weight: 800;
      font-size: 13px;
      margin-bottom: 6px;
    }
    .statusBox .msg {
      color: var(--muted);
      font-size: 12px;
      line-height: 1.35;
      white-space: pre-wrap;
    }

    @media (max-width: 1180px) {
      .container { grid-template-columns: 1fr; }
    }
  </style>
</head>

<body>
<header>
  <div class="left">
    <h1>ACE – ANI XML Extractor (Single File)</h1>
    <div class="sub">Strict gating: PDF + HTML + Scrape must match (Cite-as SECOND line). Generates Elsevier ANI XML.</div>
  </div>
  <div class="right">
    <button id="btnRun" disabled>Run Extraction</button>
    <button id="btnDownload" class="secondary" disabled>Download XML</button>
    <button id="btnClear" class="secondary">Clear</button>
  </div>
</header>

<div class="container">
  <!-- LEFT: Uploads + Rules status -->
  <section class="card">
    <div class="hd">
      <h2>Support Docs</h2>
      <span class="small">PDF + HTML + Scrape</span>
    </div>
    <div class="bd">
      <div class="field">
        <label>1) PDF (arXiv PDF)</label>
        <input id="pdfFile" type="file" accept="application/pdf" />
      </div>
      <div class="field">
        <label>2) HTML (arXiv abstract page saved as .html)</label>
        <input id="htmlFile" type="file" accept=".html,text/html" />
      </div>
      <div class="field">
        <label>3) Scrape data (JSON or TXT) – must contain ID+version somewhere</label>
        <input id="scrapeFile" type="file" accept=".json,.txt,application/json,text/plain" />
      </div>

      <div class="sp"></div>

      <div class="statusBox" id="gateBox">
        <div class="title">Gate Status</div>
        <div class="msg" id="gateMsg">Upload the 3 support docs. Extraction is blocked until gate passes.</div>
      </div>

      <div class="sp"></div>

      <div class="row" id="pills"></div>

      <div class="sp"></div>
      <div class="small">
        <div><strong>Gate Rules</strong></div>
        <div class="mono">
          IF PDF has arXiv ID → PDF ID+ver == HTML ID+ver == SCRAPE ID+ver<br/>
          ELSE (no PDF ID) → Titles(PDF vs HTML) must match (per rules) AND HTML ID+ver == SCRAPE ID+ver
        </div>
      </div>
    </div>
  </section>

  <!-- CENTER: PDF preview -->
  <section class="card">
    <div class="hd">
      <h2>PDF Preview</h2>
      <span class="small" id="pdfInfo">No PDF loaded</span>
    </div>
    <div class="bd">
      <div class="pdfWrap">
        <canvas id="pdfCanvas"></canvas>
      </div>
      <div class="row" style="margin-top:10px;">
        <button class="secondary" id="btnPrev" disabled>Prev</button>
        <button class="secondary" id="btnNext" disabled>Next</button>
        <span class="small" id="pageInfo"></span>
      </div>
    </div>
  </section>

  <!-- RIGHT: Extracted fields + XML -->
  <section class="card">
    <div class="hd">
      <h2>Extracted Data → XML</h2>
      <span class="small">Edit if needed</span>
    </div>
    <div class="bd">
      <div class="grid2">
        <div class="field">
          <label>ArXiv ID (Final)</label>
          <input id="finalId" type="text" class="mono" placeholder="e.g., 2409.09977v2" />
        </div>
        <div class="field">
          <label>Language (default ENG)</label>
          <input id="lang" type="text" value="ENG" class="mono" />
        </div>
      </div>

      <div class="field">
        <label>Title (Final)</label>
        <textarea id="finalTitle" placeholder="Title"></textarea>
      </div>

      <div class="field">
        <label>Keywords (one per line)</label>
        <textarea id="finalKeywords" placeholder="keyword 1&#10;keyword 2"></textarea>
      </div>

      <div class="field">
        <label>Abstract (Final)</label>
        <textarea id="finalAbstract" placeholder="Abstract text"></textarea>
      </div>

      <div class="field">
        <label>Authors (JSON array) – editable</label>
        <textarea id="finalAuthors" class="mono" placeholder='[{"initials":"P.","given":"Pedro","surname":"Bessa","email":"x@y.com","affiliations":[{"sourceText":"...","organization":["..."],"city":"...","postal":"...","country":"BRA"}]}]'></textarea>
      </div>

      <div class="field">
        <label>References (one per line)</label>
        <textarea id="finalRefs" placeholder="Reference 1&#10;Reference 2"></textarea>
      </div>

      <div class="field">
        <label>Generated XML (readonly)</label>
        <textarea id="xmlOut" class="mono" readonly></textarea>
      </div>
    </div>
  </section>
</div>

<script>
/* =========================
   Helpers (Normalize/Compare)
   ========================= */
function normalizeArxivId(id) {
  if (!id) return "";
  return String(id)
    .replace(/^arxiv:\s*/i, "")
    .replace(/^arXiv:\s*/i, "")
    .replace(/\s+/g, "")
    .trim();
}

function splitArxivParts(id) {
  const norm = normalizeArxivId(id);
  const m = norm.match(/(\d{4}\.\d{5})(v\d+)?/);
  if (!m) return { base: "", ver: "" };
  return { base: m[1] || "", ver: (m[2] || "") };
}

function eqStrict(a, b) {
  return normalizeArxivId(a) === normalizeArxivId(b);
}

// Title normalization for "match" check
function normalizeTitleForMatch(s) {
  if (!s) return "";
  // Keep punctuation as user warned: hyphen differences matter.
  // But remove obvious formatting artifacts:
  return String(s)
    .replace(/\s+/g, " ")
    .replace(/\u00A0/g, " ")
    .trim();
}

// Detect if "totally different" (simple heuristic)
function titleTotallyDifferent(pdfTitle, htmlTitle) {
  const a = normalizeTitleForMatch(pdfTitle).toLowerCase();
  const b = normalizeTitleForMatch(htmlTitle).toLowerCase();
  if (!a || !b) return true;
  // If shared token overlap low, call it different
  const ta = new Set(a.split(/\s+/).filter(x => x.length > 3));
  const tb = new Set(b.split(/\s+/).filter(x => x.length > 3));
  const inter = [...ta].filter(x => tb.has(x)).length;
  const minSize = Math.max(1, Math.min(ta.size, tb.size));
  return (inter / minSize) < 0.35;
}

// Choose more complete title unless totally different OR any punctuation mismatch -> choose HTML (per your "hyphen difference means choose summary")
function chooseFinalTitle(pdfTitle, htmlTitle) {
  const p = normalizeTitleForMatch(pdfTitle);
  const h = normalizeTitleForMatch(htmlTitle);
  if (!p && h) return h;
  if (!h && p) return p;
  if (!p && !h) return "";

  // If any exact-string difference includes punctuation/hyphen differences, you said: "always capture Summary title if there is any difference"
  // But also you said exception: if PDF+HTML not totally different, pick more complete.
  // We'll do:
  // 1) If totally different -> choose HTML
  if (titleTotallyDifferent(p, h)) return h;

  // 2) If not totally different -> choose longer one (more complete), BUT if there is any punctuation/hyphen mismatch, choose HTML.
  // Punctuation/hyphen mismatch check:
  const punctuationSensitiveMismatch = (p !== h);
  if (punctuationSensitiveMismatch) {
    // if mismatch exists, choose HTML (your strict rule)
    return h;
  }

  return (p.length >= h.length) ? p : h;
}

/* =========================
   HTML extraction (Cite as SECOND line)
   ========================= */
function extractArxivIdFromHtmlSummaryPage(htmlString) {
  const doc = new DOMParser().parseFromString(htmlString, "text/html");

  // Find a block containing "Cite as:"
  let citeEl = null;
  const blocks = Array.from(doc.querySelectorAll("div, section, aside, blockquote, p"));
  for (const el of blocks) {
    const t = (el.textContent || "").trim();
    if (/Cite as:/i.test(t)) { citeEl = el; break; }
  }

  let citeText = "";
  if (citeEl) {
    const tmp = citeEl.cloneNode(true);
    tmp.querySelectorAll("br").forEach(br => br.replaceWith("\n")); // CRITICAL FIX
    citeText = (tmp.textContent || "").replace(/\r/g, "").trim();
  } else {
    citeText = (doc.body?.textContent || "").replace(/\r/g, "").trim();
  }

  // Keep only portion after "Cite as:"
  const idx = citeText.toLowerCase().indexOf("cite as:");
  if (idx >= 0) citeText = citeText.slice(idx);

  const lines = citeText.split("\n").map(s => s.trim()).filter(Boolean);
  console.log("[CITE AS LINES]", lines);

  // ALWAYS prefer 2nd line (your requirement)
  const preferredLine = lines[1] || lines[0] || "";
  const lineClean = preferredLine.replace(/\[.*?\]/g, " ").trim();

  let m = lineClean.match(/arXiv:\s*(\d{4}\.\d{5})(v\d+)?/i);
  if (m) return (m[1] + (m[2] || "")).trim();

  m = lineClean.match(/(\d{4}\.\d{5})(v\d+)?/);
  if (m) return (m[1] + (m[2] || "")).trim();

  return "";
}

function extractHtmlTitle(htmlString) {
  const doc = new DOMParser().parseFromString(htmlString, "text/html");
  // arXiv abs title often in h1.title or similar
  const h1 = doc.querySelector("h1.title") || doc.querySelector("h1");
  if (h1) {
    // remove leading "Title:" if present
    const t = (h1.textContent || "").replace(/^Title:\s*/i, "").trim();
    if (t) return t;
  }
  // fallback meta
  const meta = doc.querySelector('meta[name="citation_title"]');
  if (meta?.getAttribute("content")) return meta.getAttribute("content").trim();
  // fallback title tag
  const tag = doc.querySelector("title");
  return (tag?.textContent || "").trim();
}

/* =========================
   Scrape extraction
   ========================= */
function extractArxivIdFromScrape(text) {
  if (!text) return "";
  const t = String(text);

  // Prefer explicit arXiv:....vN
  let m = t.match(/arXiv:\s*(\d{4}\.\d{5})(v\d+)?/i);
  if (m) return (m[1] + (m[2] || "")).trim();

  // Bare
  m = t.match(/(\d{4}\.\d{5})(v\d+)?/);
  if (m) return (m[1] + (m[2] || "")).trim();

  return "";
}

/* =========================
   PDF extraction (text, simple heuristics)
   ========================= */
async function readPdfTextAllPages(arrayBuffer, maxPages = 6) {
  const pdf = await pdfjsLib.getDocument({ data: arrayBuffer }).promise;
  const pages = Math.min(pdf.numPages, maxPages);
  let out = "";
  for (let i = 1; i <= pages; i++) {
    const page = await pdf.getPage(i);
    const tc = await page.getTextContent();
    const text = tc.items.map(it => it.str).join(" ");
    out += "\n\n[PAGE " + i + "]\n" + text;
  }
  return out;
}

function extractPdfArxivId(pdfText) {
  if (!pdfText) return "";
  // Usually first page has "arXiv:....vN"
  let m = pdfText.match(/arXiv:\s*(\d{4}\.\d{5})(v\d+)?/i);
  if (m) return (m[1] + (m[2] || "")).trim();
  // fallback bare
  m = pdfText.match(/(\d{4}\.\d{5})(v\d+)?/);
  if (m) return (m[1] + (m[2] || "")).trim();
  return "";
}

function extractPdfTitle(pdfText) {
  if (!pdfText) return "";
  // Very rough: take first non-empty line-ish chunk from page 1 area
  // We only have flattened text; attempt to find "Abstract" and take text before it as title region.
  const p1 = pdfText.split("[PAGE 1]")[1] || pdfText;
  const cut = p1.split(/\bAbstract\b/i)[0];
  const cleaned = cut.replace(/\s+/g, " ").trim();

  // Try to remove arXiv line and dates
  const noArxiv = cleaned.replace(/arXiv:\s*\d{4}\.\d{5}v?\d*/ig, "").trim();
  // Use first ~180 chars as "title guess" after removing author noise
  // If "Preprint" appears, drop it.
  const t = noArxiv.replace(/\bPREPRINT\b/ig, "").trim();
  return t.slice(0, 220).trim();
}

function extractPdfAbstract(pdfText) {
  if (!pdfText) return "";
  const t = pdfText.replace(/\s+/g, " ");
  // Abstract can be "Abstract", "Summary", "Synopsis", etc.
  const m = t.match(/\b(Abstract|Summary|Synopsis|Summary and Conclusions)\b[:\s]*(.+?)(\b(Introduction|1\s+Introduction|Keywords|Index Terms|References)\b)/i);
  if (m) return m[2].trim();
  return "";
}

function extractPdfKeywords(pdfText) {
  if (!pdfText) return [];
  const t = pdfText.replace(/\r/g,"");
  // headings: Keywords / Index Terms / Keywords and Phrases / Subject Headings
  const m = t.match(/\b(Keywords|Index Terms|Keywords and Phrases|Subject Headings)\b[:\s]*(.+?)(\b(Abstract|Introduction|1\s+Introduction)\b)/i);
  if (!m) return [];
  let raw = m[2].trim();

  // Remove heading word if repeated
  raw = raw.replace(/^(Keywords|Index Terms|Keywords and Phrases|Subject Headings)\s*[:\-]?\s*/i, "");

  // Split by common separators (not space)
  const parts = raw.split(/\s*[;•·,|/–—\-]\s*/).map(x => x.trim()).filter(Boolean);
  // If no separators found, return single chunk (better than fake)
  if (parts.length === 1) return [parts[0]];
  return parts;
}

function extractReferencesFromPdf(pdfText) {
  if (!pdfText) return [];
  const t = pdfText.replace(/\r/g,"");
  const idx = t.search(/\bReferences\b/i);
  if (idx < 0) return [];
  const after = t.slice(idx).replace(/\s+/g," ").trim();

  // crude split by patterns like "1." "[1]" etc
  let refs = [];
  const chunks = after.split(/\s(?=\[\d+\]|\d+\.)/).slice(1);
  refs = chunks.map(c => c.trim()).filter(c => c.length > 20);
  // fallback: split by newline markers we inserted
  if (refs.length === 0) {
    refs = after.split(" [").map(x => x.trim()).filter(x => x.length > 30);
  }
  // limit to avoid garbage
  return refs.slice(0, 200);
}

/* =========================
   Authors/Affiliations – best effort heuristic
   ========================= */
function extractAuthorsAffilsEmails(pdfText) {
  // Goal: return array of authors, each with affiliations list (sourceText)
  // This is heuristic. Your examples often have:
  // "Name 1,2* , Name 1 , Name 4 ..." then numbered affiliation lines.
  const out = [];

  if (!pdfText) return out;
  const p1 = (pdfText.split("[PAGE 1]")[1] || pdfText).replace(/\s+/g, " ").trim();

  // Try to capture a block between title guess and Abstract
  const beforeAbs = p1.split(/\bAbstract\b/i)[0] || p1;

  // Emails anywhere early/late:
  const emails = Array.from(new Set((pdfText.match(/[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,}/ig) || []).map(x => x.trim())));

  // Simple author candidate: sequences of "Firstname Lastname"
  // We'll use a conservative regex and then de-duplicate.
  const nameCandidates = (beforeAbs.match(/\b([A-Z][a-z]+(?:[-’'][A-Z][a-z]+)?\s+[A-Z][a-z]+(?:[-’'][A-Z][a-z]+)?)\b/g) || []);
  const uniqNames = [];
  for (const n of nameCandidates) {
    if (!uniqNames.includes(n) && n.length >= 5) uniqNames.push(n);
  }

  // Build 3-8 authors max from early text (avoid huge garbage)
  const authors = uniqNames.slice(0, 12);

  // Affiliation lines with leading numbers e.g. "1 Dept. of ..."
  const affilLines = [];
  const allLines = pdfText.split("\n").map(x => x.trim()).filter(Boolean);
  for (const ln of allLines) {
    if (/^\d+\s*(Dept\.|Department|School|University|Institut|Institute|Laboratory|Lab|Center|Centre|Faculty|College)\b/i.test(ln)) {
      affilLines.push(ln);
    }
  }

  // If none found, fallback: try to detect chunk with commas and country names
  if (affilLines.length === 0) {
    for (const ln of allLines) {
      if (/(University|Universit|Institute|Laborator|CNRS|INRIA|School|Dept\.|Department)/i.test(ln) && ln.length < 200) {
        affilLines.push(ln);
      }
    }
  }

  const affilMap = new Map(); // num -> text
  for (const a of affilLines) {
    const m = a.match(/^(\d+)\s*(.+)$/);
    if (m) affilMap.set(m[1], m[2].trim());
  }

  // Basic mapping: if author line contains "Name 1,2" we map those numbers
  // Try to find the author list line:
  const authorLineGuess = beforeAbs.match(/([A-Z][a-z].+?)\bAbstract\b/i)?.[1] || beforeAbs;
  const authorAffNums = new Map(); // name -> [nums]

  for (const name of authors) {
    // look near name for superscripts in flat text: "Name 1,2"
    const re = new RegExp(name.replace(/[.*+?^${}()|[\]\\]/g, "\\$&") + "\\s*([0-9][0-9,\\s]*)", "i");
    const m = authorLineGuess.match(re);
    let nums = [];
    if (m) {
      nums = m[1].split(/[, ]+/).map(x => x.trim()).filter(x => /^\d+$/.test(x));
    }
    authorAffNums.set(name, nums);
  }

  // Build output authors
  let seq = 1;
  for (const name of authors) {
    const parts = name.split(/\s+/);
    const given = parts.slice(0, -1).join(" ");
    const surname = parts[parts.length - 1] || "";
    const initials = given.split(/\s+/).map(w => (w[0] ? (w[0].toUpperCase() + ".") : "")).join("");

    // assign email if contains surname or given substring
    let email = "";
    for (const e of emails) {
      const el = e.toLowerCase();
      if (surname && el.includes(surname.toLowerCase())) { email = e; break; }
      if (given && el.includes(given.toLowerCase().split(" ")[0])) { email = e; }
    }

    const nums = authorAffNums.get(name) || [];
    const affiliations = [];
    for (const n of nums) {
      const txt = affilMap.get(n);
      if (txt) affiliations.push({ sourceText: txt });
    }

    out.push({
      seq: seq++,
      initials: initials || "",
      given: given || "",
      surname: surname || "",
      email: email || "",
      affiliations
    });
  }

  return out;
}

/* =========================
   XML Builder (ANI structure)
   ========================= */
function escXml(s) {
  return String(s ?? "")
    .replace(/&/g,"&amp;")
    .replace(/</g,"&lt;")
    .replace(/>/g,"&gt;")
    .replace(/"/g,"&quot;")
    .replace(/'/g,"&apos;");
}

function buildAniXml(payload) {
  const ts = new Date().toISOString();

  const lang = payload.lang || "ENG";
  const arxiv = normalizeArxivId(payload.arxivId);

  const kws = (payload.keywords || []).map(k =>
    `      <author-keyword>${escXml(k)}</author-keyword>`
  ).join("\n");

  // Authors -> author-groups
  let authorGroupsXml = "";
  let grpSeq = 1;

  for (const a of (payload.authors || [])) {
    // Create one group per author (matches your sample style)
    const emailXml = a.email ? `        <ce:e-address>${escXml(a.email)}</ce:e-address>\n` : "";
    const affXml = (a.affiliations && a.affiliations.length)
      ? a.affiliations.map(aff => {
          // Minimal safe: put full string in ce:source-text, you can later refine org/city parsing.
          return (
`      <affiliation>
        <ce:source-text>${escXml(aff.sourceText || "")}</ce:source-text>
      </affiliation>`
          );
        }).join("\n")
      : `      <affiliation>\n        <ce:source-text></ce:source-text>\n      </affiliation>`;

    authorGroupsXml +=
`    <author-group seq="${grpSeq}">
      <author seq="${a.seq || grpSeq}">
        <ce:initials>${escXml(a.initials || "")}</ce:initials>
        <ce:surname>${escXml(a.surname || "")}</ce:surname>
        <ce:given-name>${escXml(a.given || "")}</ce:given-name>
${emailXml.trimEnd()}
      </author>
${affXml}
    </author-group>\n`;
    grpSeq++;
  }

  const abs = payload.abstract || "";

  const refs = (payload.references || []).map((r, i) => {
    const seq = i + 1;
    return (
`      <reference seq="${seq}">
        <ref-info/>
        <ref-fulltext>${escXml(r)}</ref-fulltext>
        <ce:source-text>${escXml(r)}</ce:source-text>
      </reference>`
    );
  }).join("\n");

  const refCount = (payload.references || []).length;

  return `<?xml version="1.0" encoding="UTF-8"?>
<units xmlns="http://www.elsevier.com/xml/ani/ani" xmlns:ce="http://www.elsevier.com/xml/ani/common">
  <unit type="ARTICLE">
    <unit-info>
      <unit-id>1</unit-id>
      <order-id>unknown</order-id>
      <parcel-id>none</parcel-id>
      <supplier-id>4</supplier-id>
      <timestamp>${escXml(ts)}</timestamp>
    </unit-info>
    <unit-content>
      <bibrecord>
        <item-info>
          <status state="new"/>
          <itemidlist>
            <itemid idtype="ARXIV">${escXml(arxiv)}</itemid>
          </itemidlist>
        </item-info>
        <head>
          <citation-info>
            <citation-type code="ar"/>
            <citation-language xml:lang="${escXml(lang)}"/>
            <abstract-language xml:lang="${escXml(lang)}"/>
            <author-keywords>
${kws ? kws : ""}
            </author-keywords>
          </citation-info>
          <citation-title>
            <titletext xml:lang="${escXml(lang)}" original="y">${escXml(payload.title || "")}</titletext>
          </citation-title>
${authorGroupsXml.trimEnd()}
          <abstracts>
            <abstract original="y" xml:lang="${escXml(lang)}">
              <ce:para>${escXml(abs)}</ce:para>
            </abstract>
          </abstracts>
          <source srcid="???"/>
        </head>
        <tail>
          <bibliography refcount="${refCount}">
${refs}
          </bibliography>
        </tail>
      </bibrecord>
    </unit-content>
  </unit>
</units>`;
}

/* =========================
   UI State
   ========================= */
const els = {
  pdfFile: document.getElementById("pdfFile"),
  htmlFile: document.getElementById("htmlFile"),
  scrapeFile: document.getElementById("scrapeFile"),
  btnRun: document.getElementById("btnRun"),
  btnDownload: document.getElementById("btnDownload"),
  btnClear: document.getElementById("btnClear"),
  gateMsg: document.getElementById("gateMsg"),
  gateBox: document.getElementById("gateBox"),
  pills: document.getElementById("pills"),
  finalId: document.getElementById("finalId"),
  finalTitle: document.getElementById("finalTitle"),
  finalKeywords: document.getElementById("finalKeywords"),
  finalAbstract: document.getElementById("finalAbstract"),
  finalAuthors: document.getElementById("finalAuthors"),
  finalRefs: document.getElementById("finalRefs"),
  xmlOut: document.getElementById("xmlOut"),
  lang: document.getElementById("lang"),
  pdfCanvas: document.getElementById("pdfCanvas"),
  pdfInfo: document.getElementById("pdfInfo"),
  pageInfo: document.getElementById("pageInfo"),
  btnPrev: document.getElementById("btnPrev"),
  btnNext: document.getElementById("btnNext"),
};

let state = {
  pdf: null,
  pdfBuffer: null,
  pdfText: "",
  htmlText: "",
  scrapeText: "",
  pdfArxiv: "",
  htmlArxiv: "",
  scrapeArxiv: "",
  pdfTitle: "",
  htmlTitle: "",
  gateOk: false,
  gateReason: "",
  pdfDoc: null,
  pageNum: 1,
};

function setPills(items) {
  els.pills.innerHTML = "";
  for (const it of items) {
    const span = document.createElement("span");
    span.className = `pill ${it.kind || ""}`;
    span.innerHTML = `<strong>${it.label}</strong> <span class="mono">${escXml(it.value || "")}</span>`;
    els.pills.appendChild(span);
  }
}

function setGate(ok, msg) {
  state.gateOk = ok;
  els.btnRun.disabled = !ok;
  els.gateBox.style.borderColor = ok ? "rgba(61,220,151,.35)" : "rgba(255,92,119,.35)";
  els.gateMsg.textContent = msg;
}

function readFileAsText(file) {
  return new Promise((res, rej) => {
    const fr = new FileReader();
    fr.onload = () => res(fr.result);
    fr.onerror = rej;
    fr.readAsText(file);
  });
}

function readFileAsArrayBuffer(file) {
  return new Promise((res, rej) => {
    const fr = new FileReader();
    fr.onload = () => res(fr.result);
    fr.onerror = rej;
    fr.readAsArrayBuffer(file);
  });
}

/* =========================
   PDF render
   ========================= */
async function renderPdfPage() {
  if (!state.pdfDoc) return;
  const page = await state.pdfDoc.getPage(state.pageNum);
  const viewport = page.getViewport({ scale: 1.4 });
  const canvas = els.pdfCanvas;
  const ctx = canvas.getContext("2d");
  canvas.width = viewport.width;
  canvas.height = viewport.height;
  await page.render({ canvasContext: ctx, viewport }).promise;

  els.pageInfo.textContent = `Page ${state.pageNum} / ${state.pdfDoc.numPages}`;
  els.btnPrev.disabled = state.pageNum <= 1;
  els.btnNext.disabled = state.pageNum >= state.pdfDoc.numPages;
}

els.btnPrev.addEventListener("click", async () => {
  if (!state.pdfDoc) return;
  state.pageNum = Math.max(1, state.pageNum - 1);
  await renderPdfPage();
});
els.btnNext.addEventListener("click", async () => {
  if (!state.pdfDoc) return;
  state.pageNum = Math.min(state.pdfDoc.numPages, state.pageNum + 1);
  await renderPdfPage();
});

/* =========================
   Gate Evaluation
   ========================= */
function evaluateGate() {
  const pills = [];

  pills.push({ label: "PDF ID", value: state.pdfArxiv || "(none)", kind: state.pdfArxiv ? "ok" : "warn" });
  pills.push({ label: "HTML ID", value: state.htmlArxiv || "(none)", kind: state.htmlArxiv ? "ok" : "bad" });
  pills.push({ label: "SCRAPE ID", value: state.scrapeArxiv || "(none)", kind: state.scrapeArxiv ? "ok" : "bad" });

  pills.push({ label: "PDF Title", value: (state.pdfTitle || "").slice(0,60), kind: state.pdfTitle ? "" : "warn" });
  pills.push({ label: "HTML Title", value: (state.htmlTitle || "").slice(0,60), kind: state.htmlTitle ? "" : "warn" });

  setPills(pills);

  // Must have HTML + SCRAPE IDs always (because we need at least that)
  if (!state.htmlArxiv || !state.scrapeArxiv) {
    setGate(false, "Blocked: HTML and Scrape must provide an arXiv ID (Cite as SECOND line + scrape text).");
    return;
  }

  const pdfHasId = !!state.pdfArxiv;

  if (pdfHasId) {
    // Strict: all three must match (including version)
    const ok = eqStrict(state.pdfArxiv, state.htmlArxiv) && eqStrict(state.htmlArxiv, state.scrapeArxiv);
    if (!ok) {
      setGate(false,
        "HOLD: Version mismatched (strict). Required: PDF == HTML == SCRAPE (ID+version).\n" +
        `PDF: ${normalizeArxivId(state.pdfArxiv)}\nHTML: ${normalizeArxivId(state.htmlArxiv)}\nSCRAPE: ${normalizeArxivId(state.scrapeArxiv)}`
      );
      return;
    }
    setGate(true, "OK: PDF/HTML/SCRAPE ID+version match. You can run extraction.");
    return;
  }

  // ELSE: PDF has no arXiv ID -> Title must match first, then HTML+scrape must match.
  const finalTitle = chooseFinalTitle(state.pdfTitle, state.htmlTitle);
  const titlesMatch = !titleTotallyDifferent(state.pdfTitle, state.htmlTitle) && normalizeTitleForMatch(finalTitle) !== "";

  if (!titlesMatch) {
    setGate(false,
      "HOLD: PDF has NO ID, so Title gate failed.\n" +
      "Required: PDF Title and HTML Title must match (per your rules) before checking HTML vs Scrape IDs."
    );
    return;
  }

  const ok2 = eqStrict(state.htmlArxiv, state.scrapeArxiv);
  if (!ok2) {
    setGate(false,
      "HOLD: PDF has NO ID, Titles match, but HTML vs SCRAPE ID+version mismatch.\n" +
      `HTML: ${normalizeArxivId(state.htmlArxiv)}\nSCRAPE: ${normalizeArxivId(state.scrapeArxiv)}`
    );
    return;
  }

  setGate(true, "OK: PDF has no ID, Titles match, and HTML == SCRAPE ID+version. You can run extraction.");
}

/* =========================
   File Listeners
   ========================= */
els.pdfFile.addEventListener("change", async (e) => {
  const f = e.target.files?.[0];
  if (!f) return;

  state.pdfBuffer = await readFileAsArrayBuffer(f);
  state.pdfDoc = await pdfjsLib.getDocument({ data: state.pdfBuffer }).promise;
  state.pageNum = 1;
  els.pdfInfo.textContent = `${f.name} (${state.pdfDoc.numPages} pages)`;
  els.btnPrev.disabled = false;
  els.btnNext.disabled = false;
  await renderPdfPage();

  // Extract text (first pages)
  state.pdfText = await readPdfTextAllPages(state.pdfBuffer, 6);
  state.pdfArxiv = extractPdfArxivId(state.pdfText);
  state.pdfTitle = extractPdfTitle(state.pdfText);

  evaluateGate();
});

els.htmlFile.addEventListener("change", async (e) => {
  const f = e.target.files?.[0];
  if (!f) return;
  state.htmlText = await readFileAsText(f);

  state.htmlArxiv = extractArxivIdFromHtmlSummaryPage(state.htmlText); // SECOND line fix
  state.htmlTitle = extractHtmlTitle(state.htmlText);

  evaluateGate();
});

els.scrapeFile.addEventListener("change", async (e) => {
  const f = e.target.files?.[0];
  if (!f) return;
  const t = await readFileAsText(f);

  // if json, stringify safely
  let text = t;
  try {
    const obj = JSON.parse(t);
    text = JSON.stringify(obj);
  } catch {}
  state.scrapeText = text;

  state.scrapeArxiv = extractArxivIdFromScrape(state.scrapeText);

  evaluateGate();
});

/* =========================
   Run extraction
   ========================= */
els.btnRun.addEventListener("click", () => {
  if (!state.gateOk) return;

  // Final ID: prefer PDF id if exists; else HTML (since HTML==scrape in that case)
  const finalId = normalizeArxivId(state.pdfArxiv || state.htmlArxiv || state.scrapeArxiv);

  // Titles
  const finalTitle = chooseFinalTitle(state.pdfTitle, state.htmlTitle);

  // Keywords + abstract from PDF (best effort). If none, keep empty rather than fake.
  const keywords = extractPdfKeywords(state.pdfText);
  const abs = extractPdfAbstract(state.pdfText);

  // Authors + affiliations (best effort)
  const authors = extractAuthorsAffilsEmails(state.pdfText);

  // References (best effort)
  const refs = extractReferencesFromPdf(state.pdfText);

  // Fill UI editable fields
  els.finalId.value = finalId;
  els.finalTitle.value = finalTitle || "";
  els.finalKeywords.value = (keywords || []).join("\n");
  els.finalAbstract.value = abs || "";
  els.finalAuthors.value = JSON.stringify(authors, null, 2);
  els.finalRefs.value = (refs || []).join("\n");

  // Build XML
  rebuildXml();
  els.btnDownload.disabled = false;
});

function rebuildXml() {
  let authors = [];
  try { authors = JSON.parse(els.finalAuthors.value || "[]"); } catch { authors = []; }

  const keywords = (els.finalKeywords.value || "")
    .split("\n").map(x => x.trim()).filter(Boolean);

  const refs = (els.finalRefs.value || "")
    .split("\n").map(x => x.trim()).filter(Boolean);

  const payload = {
    arxivId: els.finalId.value.trim(),
    lang: els.lang.value.trim() || "ENG",
    title: els.finalTitle.value.trim(),
    keywords,
    abstract: els.finalAbstract.value.trim(),
    authors,
    references: refs,
  };

  const xml = buildAniXml(payload);
  els.xmlOut.value = xml;
}

["finalId","lang","finalTitle","finalKeywords","finalAbstract","finalAuthors","finalRefs"]
  .forEach(id => document.getElementById(id).addEventListener("input", rebuildXml));

/* =========================
   Download XML
   ========================= */
els.btnDownload.addEventListener("click", () => {
  const xml = els.xmlOut.value || "";
  if (!xml.trim()) return;

  const blob = new Blob([xml], { type: "application/xml;charset=utf-8" });
  const url = URL.createObjectURL(blob);
  const a = document.createElement("a");
  const id = normalizeArxivId(els.finalId.value || "output");
  a.href = url;
  a.download = `${id || "output"}.xml`;
  document.body.appendChild(a);
  a.click();
  a.remove();
  URL.revokeObjectURL(url);
});

/* =========================
   Clear
   ========================= */
els.btnClear.addEventListener("click", () => {
  state = {
    pdf: null,
    pdfBuffer: null,
    pdfText: "",
    htmlText: "",
    scrapeText: "",
    pdfArxiv: "",
    htmlArxiv: "",
    scrapeArxiv: "",
    pdfTitle: "",
    htmlTitle: "",
    gateOk: false,
    gateReason: "",
    pdfDoc: null,
    pageNum: 1,
  };
  els.pdfFile.value = "";
  els.htmlFile.value = "";
  els.scrapeFile.value = "";

  els.pdfInfo.textContent = "No PDF loaded";
  els.pageInfo.textContent = "";
  els.btnPrev.disabled = true;
  els.btnNext.disabled = true;

  els.finalId.value = "";
  els.finalTitle.value = "";
  els.finalKeywords.value = "";
  els.finalAbstract.value = "";
  els.finalAuthors.value = "";
  els.finalRefs.value = "";
  els.xmlOut.value = "";
  els.btnDownload.disabled = true;

  setPills([]);
  setGate(false, "Upload the 3 support docs. Extraction is blocked until gate passes.");
});

setGate(false, "Upload the 3 support docs. Extraction is blocked until gate passes.");
</script>
</body>
</html>
