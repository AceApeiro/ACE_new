<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>ACE – Zip Extractor (arXiv)</title>

  <!-- JSZip -->
  <script src="https://cdn.jsdelivr.net/npm/jszip@3.10.1/dist/jszip.min.js"></script>

  <!-- PDF.js -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>

  <style>
    :root{
      --bg:#0b0f14; --panel:#111827; --panel2:#0f172a; --muted:#94a3b8;
      --text:#e5e7eb; --good:#22c55e; --bad:#ef4444; --warn:#f59e0b; --line:#1f2937;
      --btn:#2563eb; --btn2:#334155;
    }
    *{box-sizing:border-box}
    body{margin:0; font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Arial; background:var(--bg); color:var(--text)}
    .wrap{max-width:1400px; margin:0 auto; padding:14px}
    .top{display:flex; gap:10px; align-items:center; flex-wrap:wrap}
    .card{background:linear-gradient(180deg,var(--panel),var(--panel2)); border:1px solid var(--line); border-radius:14px; padding:12px}
    .grow{flex:1}
    .row{display:flex; gap:12px; margin-top:12px}
    .colL{width:320px; min-width:280px}
    .colR{flex:1; min-width:320px}
    .h{display:flex; align-items:center; justify-content:space-between; gap:10px; margin-bottom:8px}
    .title{font-size:14px; font-weight:700}
    .muted{color:var(--muted); font-size:12px}
    .btn{border:0; background:var(--btn); color:white; padding:10px 12px; border-radius:10px; cursor:pointer; font-weight:700}
    .btn.secondary{background:var(--btn2)}
    .btn:disabled{opacity:.5; cursor:not-allowed}
    input[type="file"]{display:none}
    .fileLabel{display:inline-flex; gap:10px; align-items:center; border:1px dashed #334155; padding:10px 12px; border-radius:12px; cursor:pointer}
    .list{max-height:420px; overflow:auto; border-top:1px solid var(--line); margin-top:10px; padding-top:10px}
    .item{padding:10px; border:1px solid var(--line); border-radius:12px; margin-bottom:8px; cursor:pointer; background:#0b1220}
    .item.active{outline:2px solid #2563eb}
    .badge{font-size:11px; padding:3px 8px; border-radius:999px; border:1px solid var(--line); background:#0b1220}
    .badge.good{border-color:rgba(34,197,94,.6); color:var(--good)}
    .badge.bad{border-color:rgba(239,68,68,.6); color:var(--bad)}
    .badge.warn{border-color:rgba(245,158,11,.6); color:var(--warn)}
    .grid{display:grid; grid-template-columns: 1.35fr .65fr; gap:12px}
    .tabs{display:flex; gap:8px; flex-wrap:wrap}
    .tab{padding:8px 10px; border-radius:10px; border:1px solid var(--line); background:#0b1220; cursor:pointer; font-weight:700; font-size:12px}
    .tab.active{border-color:#2563eb}
    .pane{display:none}
    .pane.active{display:block}
    .box{border:1px solid var(--line); border-radius:12px; overflow:hidden; background:#050a12}
    .boxHead{padding:8px 10px; border-bottom:1px solid var(--line); display:flex; align-items:center; justify-content:space-between}
    .boxBody{padding:10px}
    textarea{width:100%; min-height:220px; background:#050a12; color:var(--text); border:1px solid var(--line); border-radius:12px; padding:10px; font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace; font-size:12px}
    .kv{display:grid; grid-template-columns: 160px 1fr; gap:8px; font-size:13px}
    .k{color:var(--muted)}
    .statusLine{display:flex; gap:8px; flex-wrap:wrap; align-items:center}
    canvas{width:100%; height:auto; background:#0b1220; border-radius:10px}
    .htmlPreview{max-height:520px; overflow:auto; background:white; color:black; border-radius:10px; padding:10px}
    .small{font-size:12px}
    .hr{height:1px; background:var(--line); margin:10px 0}
    .mono{font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace}
  </style>
</head>

<body>
<div class="wrap">

  <div class="top card">
    <div class="grow">
      <div style="display:flex;align-items:center;justify-content:space-between;gap:10px;flex-wrap:wrap">
        <div>
          <div style="font-size:16px;font-weight:900;letter-spacing:.2px">ACE – Apeiro Citation Extractor (arXiv ZIP)</div>
          <div class="muted">Upload ZIP with PDF + API XML + Scrape XML + HTML summary. Strict validation → hold if mismatch. Generate final Elsevier XML.</div>
        </div>

        <div style="display:flex;gap:10px;align-items:center;flex-wrap:wrap">
          <label class="fileLabel">
            <span class="badge">ZIP</span>
            <span class="small">Choose ZIP</span>
            <input id="zipInput" type="file" accept=".zip" />
          </label>

          <button id="runBtn" class="btn" disabled>Run Extraction</button>
          <button id="downloadBtn" class="btn secondary" disabled>Download XML</button>
        </div>
      </div>

      <div class="hr"></div>

      <div class="statusLine">
        <span class="badge" id="zipBadge">No ZIP loaded</span>
        <span class="muted" id="hint">Tip: open DevTools Console if something doesn’t load.</span>
      </div>
    </div>
  </div>

  <div class="row">
    <!-- LEFT -->
    <div class="colL card">
      <div class="h">
        <div class="title">PDFs in ZIP</div>
        <div class="muted" id="fileCount">0</div>
      </div>

      <div class="muted">Select a PDF. ACE auto-pairs support docs by reading their content.</div>
      <div class="list" id="fileList"></div>
    </div>

    <!-- RIGHT -->
    <div class="colR">
      <div class="grid">

        <!-- PREVIEW -->
        <div class="card">
          <div class="h">
            <div class="title">Preview</div>
            <div class="tabs">
              <div class="tab active" data-tab="pdfPane">PDF</div>
              <div class="tab" data-tab="htmlPane">HTML Summary</div>
              <div class="tab" data-tab="apiPane">API XML</div>
              <div class="tab" data-tab="scrapePane">Scrape XML</div>
            </div>
          </div>

          <div id="pdfPane" class="pane active">
            <div class="box">
              <div class="boxHead">
                <div class="small muted">PDF rendered via PDF.js</div>
                <div style="display:flex;gap:8px;align-items:center">
                  <button class="btn secondary" id="prevPageBtn" disabled>Prev</button>
                  <span class="badge mono" id="pageInfo">- / -</span>
                  <button class="btn secondary" id="nextPageBtn" disabled>Next</button>
                </div>
              </div>
              <div class="boxBody">
                <canvas id="pdfCanvas"></canvas>
              </div>
            </div>
          </div>

          <div id="htmlPane" class="pane">
            <div class="box">
              <div class="boxHead">
                <div class="small muted">HTML is sanitized (scripts removed).</div>
              </div>
              <div class="boxBody">
                <div id="htmlPreview" class="htmlPreview">No HTML loaded.</div>
              </div>
            </div>
          </div>

          <div id="apiPane" class="pane">
            <textarea id="apiText" readonly placeholder="API XML preview..."></textarea>
          </div>

          <div id="scrapePane" class="pane">
            <textarea id="scrapeText" readonly placeholder="Scrape XML preview..."></textarea>
          </div>
        </div>

        <!-- EXTRACTION -->
        <div class="card">
          <div class="h">
            <div class="title">Extraction</div>
            <span class="badge" id="selectedSet">No set selected</span>
          </div>

          <div class="box">
            <div class="boxHead">
              <div class="small muted">Strict validation checks</div>
            </div>
            <div class="boxBody">
              <div class="kv">
                <div class="k">Detected arXiv ID (PDF)</div><div class="mono" id="pdfIdVal">—</div>
                <div class="k">Detected version (PDF)</div><div class="mono" id="pdfVerVal">—</div>

                <div class="k">Detected arXiv ID (HTML)</div><div class="mono" id="htmlIdVal">—</div>
                <div class="k">Detected version (HTML)</div><div class="mono" id="htmlVerVal">—</div>

                <div class="k">Detected arXiv ID (Scrape)</div><div class="mono" id="scrIdVal">—</div>
                <div class="k">Detected version (Scrape)</div><div class="mono" id="scrVerVal">—</div>

                <div class="k">Title check (PDF vs HTML)</div><div id="titleCheckVal">—</div>
                <div class="k">ID/Version check</div><div id="matchVal">—</div>

                <div class="k">Chosen title</div><div id="titleVal">—</div>
                <div class="k">Abstract found?</div><div id="absVal">—</div>
                <div class="k">Keywords found?</div><div id="kwVal">—</div>
                <div class="k">Authors</div><div id="authVal">—</div>
                <div class="k">Affiliations</div><div id="affVal">—</div>
                <div class="k">References</div><div id="refVal">—</div>
              </div>
            </div>
          </div>

          <div class="hr"></div>

          <div class="title" style="margin-bottom:8px">Generated XML</div>
          <textarea id="outXml" placeholder="Run Extraction to generate XML..." spellcheck="false"></textarea>
        </div>

      </div>
    </div>
  </div>
</div>

<script>
  // PDF.js worker
  pdfjsLib.GlobalWorkerOptions.workerSrc =
    "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";

  // ----------------------------
  // State
  // ----------------------------
  const state = {
    zip: null,
    fileNames: [],
    pdfs: [],
    selectedPdf: null,
    selected: { pdfName:null, apiName:null, scrapeName:null, htmlName:null },
    pdfDoc: null,
    pdfPageNum: 1,
    pdfPageCount: 0,
    pdfTextByPage: new Map(), // pageNum -> text
  };

  // ----------------------------
  // UI refs
  // ----------------------------
  const zipInput = document.getElementById("zipInput");
  const runBtn = document.getElementById("runBtn");
  const downloadBtn = document.getElementById("downloadBtn");

  const zipBadge = document.getElementById("zipBadge");
  const fileCount = document.getElementById("fileCount");
  const fileList = document.getElementById("fileList");
  const selectedSet = document.getElementById("selectedSet");

  const apiText = document.getElementById("apiText");
  const scrapeText = document.getElementById("scrapeText");
  const htmlPreview = document.getElementById("htmlPreview");

  const pdfIdVal = document.getElementById("pdfIdVal");
  const pdfVerVal = document.getElementById("pdfVerVal");
  const htmlIdVal = document.getElementById("htmlIdVal");
  const htmlVerVal = document.getElementById("htmlVerVal");
  const scrIdVal = document.getElementById("scrIdVal");
  const scrVerVal = document.getElementById("scrVerVal");

  const titleCheckVal = document.getElementById("titleCheckVal");
  const matchVal = document.getElementById("matchVal");
  const titleVal = document.getElementById("titleVal");
  const absVal = document.getElementById("absVal");
  const kwVal = document.getElementById("kwVal");
  const authVal = document.getElementById("authVal");
  const affVal = document.getElementById("affVal");
  const refVal = document.getElementById("refVal");

  const outXml = document.getElementById("outXml");

  const pdfCanvas = document.getElementById("pdfCanvas");
  const prevPageBtn = document.getElementById("prevPageBtn");
  const nextPageBtn = document.getElementById("nextPageBtn");
  const pageInfo = document.getElementById("pageInfo");

  // Tabs
  document.querySelectorAll(".tab").forEach(t => {
    t.addEventListener("click", () => {
      document.querySelectorAll(".tab").forEach(x => x.classList.remove("active"));
      document.querySelectorAll(".pane").forEach(p => p.classList.remove("active"));
      t.classList.add("active");
      document.getElementById(t.dataset.tab).classList.add("active");
    });
  });

  // ----------------------------
  // Helpers
  // ----------------------------
  const lower = s => (s || "").toLowerCase();

  function escapeHtml(s) {
    return String(s ?? "").replace(/[&<>"']/g, c => ({
      "&":"&amp;","<":"&lt;",">":"&gt;",'"':"&quot;","'":"&#039;"
    }[c]));
  }

  function badge(text, kind="") {
    const cls = kind ? `badge ${kind}` : "badge";
    return `<span class="${cls}">${escapeHtml(text)}</span>`;
  }

  function stripScripts(html) {
    const doc = new DOMParser().parseFromString(html, "text/html");
    doc.querySelectorAll("script, iframe, object, embed").forEach(n => n.remove());
    doc.querySelectorAll("*").forEach(el => {
      [...el.attributes].forEach(a => {
        if (a.name.startsWith("on")) el.removeAttribute(a.name);
      });
    });
    return doc.body.innerHTML || "";
  }

  function escapeXml(s){
    return String(s||"").replace(/[<>&'"]/g, c => ({'<':'&lt;','>':'&gt;','&':'&amp;',"'":'&apos;','"':'&quot;'}[c]));
  }

  // arXiv ID patterns
  const ARXIV_ID_RE = /(\d{4}\.\d{4,5})(v\d+)?/i;

  function normId(id){ return (id||"").trim(); }
  function normVer(v){ return (v||"").trim(); } // expects v2, v3

  function extractArxivFromText(text) {
    if (!text) return { id:null, version:null };
    const m1 = /arxiv:\s*(\d{4}\.\d{4,5})(v\d+)?/i.exec(text);
    if (m1) return { id: m1[1], version: (m1[2]||null) };

    const m2 = /oai:arxiv\.org:(\d{4}\.\d{4,5})/i.exec(text);
    if (m2) return { id: m2[1], version: null };

    const m3 = ARXIV_ID_RE.exec(text);
    if (m3) return { id: m3[1], version: (m3[2]||null) };

    return { id:null, version:null };
  }

  // XML helpers
  function xmlText(node, tagName) {
    const el = node.getElementsByTagName(tagName)[0];
    return el ? (el.textContent || "").trim() : "";
  }

  // --- HTML landing page (arXiv abstract page) ---
  // MUST prefer "Cite as" second line when present:
  //   (or arXiv:NNNN.NNNNNvX [cat] for this version)
  function extractArxivFromCiteAs(htmlStr) {
    if (!htmlStr) return { id: null, version: null };

    const s = String(htmlStr)
      .replace(/&nbsp;/gi, " ")
      .replace(/\u00a0/g, " ")
      .replace(/\s+/g, " ");

    // 1) Prefer explicit second line
    let m = s.match(/\(\s*or\s+arxiv:\s*([0-9]{4}\.[0-9]{4,5})\s*(v\d+)\b/i);
    if (m) return { id: m[1], version: m[2] };

    // 2) Variant formatting
    m = s.match(/arxiv:\s*([0-9]{4}\.[0-9]{4,5})\s*(v\d+)\b[^\n\r]{0,180}for\s+this\s+version/i);
    if (m) return { id: m[1], version: m[2] };

    // 3) Window around "Cite as"
    const low = s.toLowerCase();
    const idx = low.indexOf("cite as");
    const win = idx >= 0 ? s.slice(idx, idx + 800) : s;

    m = win.match(/arxiv:\s*([0-9]{4}\.[0-9]{4,5})\s*(v\d+)\b/i);
    if (m) return { id: m[1], version: m[2] };

    m = win.match(/arxiv:\s*([0-9]{4}\.[0-9]{4,5})\b/i);
    return { id: m ? m[1] : null, version: null };
  }

  // --- API XML (arXiv OAI) ---
  function parseApiXml(xmlStr) {
    const doc = new DOMParser().parseFromString(xmlStr, "text/xml");

    const idRaw = xmlText(doc, "id");
    const { id } = extractArxivFromText(idRaw);

    const title = xmlText(doc, "title");
    const abstract = xmlText(doc, "abstract");

    const authors = [...doc.getElementsByTagName("author")].map(a => ({
      rawName: "",
      keyname: xmlText(a, "keyname"),
      forenames: xmlText(a, "forenames"),
      initials: "",
      given: "",
      surname: "",
      markers: [],
      emails: [],
      orcid: null,
      degrees: [],
      suffix: null,
      source: "API",
      affiliations: []
    }));

    const orcidMatches = [...xmlStr.matchAll(/<[^:>]*:orcid>([^<]+)<\/[^:>]*:orcid>/gi)].map(m => (m[1]||"").trim());
    if (orcidMatches.length && authors.length) {
      for (let i=0;i<Math.min(authors.length, orcidMatches.length);i++){
        authors[i].orcid = orcidMatches[i];
      }
    }

    // Normalize author fields
    for (const a of authors){
      a.surname = (a.keyname || "").trim();
      a.given = (a.forenames || "").trim();
      a.initials = makeInitials(a.given);
    }

    return { id: id || "", title, abstract, authors };
  }

  // --- Scrape XML ---
  function parseScrapeXml(xmlStr) {
    const doc = new DOMParser().parseFromString(xmlStr, "text/xml");
    const item = doc.getElementsByTagName("item")[0];
    let id = (item?.getAttribute("id") || "").trim();

    let version = "";
    const v = doc.getElementsByTagName("version")[0];
    if (v) {
      const number = v.getAttribute("number") || "";
      const m = /\[v(\d+)\]/i.exec(number);
      if (m) version = "v" + m[1];
    }

    const allText = doc.documentElement?.textContent || "";
    if (!version || !id) {
      const ex = extractArxivFromText(allText);
      if (!id && ex.id) id = ex.id;
      if (!version && ex.version) version = ex.version;
    }

    return { id, version };
  }

  // --- HTML landing ---
  function parseHtmlLanding(htmlStr) {
    const doc = new DOMParser().parseFromString(htmlStr, "text/html");
    const bodyText = doc.body?.textContent || "";

    let { id, version } = extractArxivFromCiteAs(htmlStr);

    if (!id) {
      const t = (doc.body?.innerText || doc.documentElement?.innerText || "");
      ({ id, version } = extractArxivFromText(t));
    }

    let title = (doc.querySelector('meta[name="citation_title"]')?.getAttribute("content") || "").trim();
    if (!title) title = (doc.title || "").trim();

    let abstract = (doc.querySelector('meta[name="citation_abstract"]')?.getAttribute("content") || "").trim();
    if (!abstract) {
      const fullText = bodyText.replace(/\s+/g," ").trim();
      const idx = fullText.toLowerCase().indexOf("abstract");
      if (idx !== -1){
        const slice = fullText.slice(idx);
        const stop = slice.search(/\b(comments|subjects|cite as|submission history|full-text links|references|bibliography)\b/i);
        abstract = (stop > 0 ? slice.slice(0, stop) : slice)
          .replace(/\babstract\b\s*:?/i,"")
          .trim();
      }
    }

    return { id: id||"", version: version||"", title, abstract, sanitizedHtml: stripScripts(htmlStr), bodyText };
  }

  function makeInitials(given){
    const parts = String(given||"").split(/\s+/).filter(Boolean);
    if (!parts.length) return "";
    // Keep hyphenated initials: "Brice-Olivier" -> "B.-O."
    const ini = parts.map(p=>{
      if (p.includes("-")){
        return p.split("-").filter(Boolean).map(x => (x[0]?x[0].toUpperCase() + ".":"")).join("-");
      }
      return p[0] ? p[0].toUpperCase() + "." : "";
    }).join("");
    return ini;
  }

  // ----------------------------
  // Title rules
  // ----------------------------
  function cleanTitleForCompare(s){
    return String(s||"")
      .replace(/\bpreprint\b/ig, "")
      .replace(/\*/g,"")
      .replace(/\s+/g," ")
      .trim();
  }
  function titlesExactlySame(pdfTitle, htmlTitle){
    return cleanTitleForCompare(pdfTitle) === cleanTitleForCompare(htmlTitle);
  }
  function chooseTitle(pdfTitle, htmlTitle){
    const p = (pdfTitle||"").trim();
    const h = (htmlTitle||"").trim();
    if (!p && h) return h;
    if (!h && p) return p;
    if (!p && !h) return "";
    if (!roughlySimilar(p, h)) return h;
    return (p.length >= h.length) ? p : h;
  }
  function roughlySimilar(a,b){
    const na = a.toLowerCase().replace(/[^a-z0-9\s]/g," ").split(/\s+/).filter(Boolean);
    const nb = b.toLowerCase().replace(/[^a-z0-9\s]/g," ").split(/\s+/).filter(Boolean);
    if (!na.length || !nb.length) return false;
    const setA = new Set(na);
    let hit = 0;
    for (const w of nb) if (setA.has(w)) hit++;
    const ratio = hit / Math.max(na.length, nb.length);
    return ratio >= 0.55;
  }

  // ----------------------------
  // Keywords (STRICT: only explicit heading lines)
  // ----------------------------
  const KW_LABEL_RE = /^\s*(keywords?|key\s*words?|index\s*terms|keywords?\s*and\s*phrases|subject\s*headings)\s*[:\-–—]\s*(.+)$/i;

  function extractKeywordsStrictFromPdfText(fullPdfText){
    if (!fullPdfText) return [];
    // look for a clean line like: "Keywords: a, b, c"
    const lines = fullPdfText.replace(/\r/g,"\n").split("\n").map(l=>l.trim()).filter(Boolean);

    for (let i=0;i<Math.min(lines.length, 4000);i++){
      const l = lines[i];
      const m = KW_LABEL_RE.exec(l);
      if (!m) continue;

      // Sometimes keywords spill to next line (rare). If current line looks short and next line is not a section header, append.
      let payload = (m[2]||"").trim();
      const next = lines[i+1] || "";
      if (payload.length < 25 && next && !/^\s*(abstract|introduction|1\.\s*introduction|references|bibliography)\b/i.test(next) && next.length < 220) {
        // only append if next line looks like continuation (contains commas or semicolons)
        if (/[;,]/.test(next) || next.split(/\s+/).length <= 18) {
          payload += " " + next.trim();
        }
      }

      return splitKeywordPayload(payload);
    }

    // If no explicit keyword label line, DO NOT extract anything.
    return [];
  }

  function splitKeywordPayload(payload){
    if (!payload) return [];
    let s = payload.replace(/\s+/g," ").trim();

    // strip trailing period if it's clearly sentence-ending
    s = s.replace(/\.\s*$/,"").trim();

    // split by commas/semicolons/bullets
    let parts = s.split(/[;•\u2022|·\u00b7]+/).flatMap(x => x.split(",")).map(x=>x.trim()).filter(Boolean);

    // remove obviously wrong fragments
    parts = parts
      .map(k => k.replace(/\s*\(\s*\)$/g,"").trim())
      .map(k => k.replace(/\s*(\d+)(\*|†|‡)?\s*$/g,"").trim())
      .filter(k => k.length >= 2 && k.length <= 140);

    // de-dupe
    const seen = new Set();
    const out = [];
    for (const k of parts){
      const key = k.toLowerCase();
      if (!seen.has(key)){
        seen.add(key);
        out.push(k);
      }
    }
    return out.slice(0, 25);
  }

  // ----------------------------
  // Abstract (keep safe)
  // ----------------------------
  function stripTeXMath(s){
    if (!s) return "";
    let t = String(s);
    t = t.replace(/\$([^$]{1,30})\$/g, (_, inner) => inner);
    t = t.replace(/\$([^$]{31,})\$/g, "(Formula presented)");
    t = t.replace(/\\\\/g,"\\");
    t = t.replace(/\\mathcal\{[^}]+\}/g, "(Formula presented)");
    t = t.replace(/\\[a-zA-Z]+(\{[^}]*\})?/g, "(Formula presented)");
    t = t.replace(/\(Formula presented\)(\s*\(Formula presented\))+/g,"(Formula presented)");
    return t.replace(/\s+/g," ").trim();
  }

  // ----------------------------
  // Sup/Sub conversion for XML
  // ----------------------------
  const SUPER_MAP = {
    "⁰":"0","¹":"1","²":"2","³":"3","⁴":"4","⁵":"5","⁶":"6","⁷":"7","⁸":"8","⁹":"9",
    "⁻":"−","⁺":"+"
  };
  const SUB_MAP = {
    "₀":"0","₁":"1","₂":"2","₃":"3","₄":"4","₅":"5","₆":"6","₇":"7","₈":"8","₉":"9"
  };

  function applySupSubXml(text){
    if (!text) return "";
    let out = "";
    for (const ch of String(text)){
      if (SUPER_MAP[ch] !== undefined){
        out += `<sup>${escapeXml(SUPER_MAP[ch])}</sup>`;
      } else if (SUB_MAP[ch] !== undefined){
        out += `<inf>${escapeXml(SUB_MAP[ch])}</inf>`;
      } else {
        out += escapeXml(ch);
      }
    }
    return out;
  }

  // ----------------------------
  // References (better splitting + remove numbering)
  // ----------------------------
  function normalizeRefLine(line){
    let l = String(line||"").trim();
    // remove leading numbering markers: (1), [1], 1.
    l = l.replace(/^\(?\s*\d+\s*\)?\s*[\.\]]?\s*/,"");
    l = l.replace(/^\[\s*\d+\s*\]\s*/,"");
    // remove obvious page header noise like "33" alone
    if (/^\d{1,4}$/.test(l)) return "";
    return l.trim();
  }

  function extractReferencesFromPdfTextBetter(pdfText){
    if (!pdfText) return [];
    const t = pdfText.replace(/\r/g,"\n");
    const low = t.toLowerCase();
    let start = Math.max(low.lastIndexOf("\nreferences"), low.lastIndexOf("\nbibliography"));
    if (start < 0) start = Math.max(low.lastIndexOf("references\n"), low.lastIndexOf("bibliography\n"));
    if (start < 0) return [];

    let tail = t.slice(start);
    tail = tail.replace(/^\s*(references|bibliography)\s*/i,"").trim();

    const lines = tail.split("\n").map(l=>l.trim()).filter(Boolean);

    const refs = [];
    let cur = "";

    // start of a new reference:
    // [AB24] style, [1] style, (1) style, 1. style
    const isNew = (l) =>
      /^\[[A-Za-z0-9]{1,10}[\sA-Za-z0-9+]*\]/.test(l) ||
      /^\[\s*\d+\s*\]/.test(l) ||
      /^\(\s*\d+\s*\)/.test(l) ||
      /^\d+\.\s+/.test(l);

    const isArxivOnly = (l) => /^arxiv:\s*\d{4}\.\d{4,5}/i.test(l);

    function pushCur(){
      const r = cur.replace(/\s+/g," ").trim();
      if (r && r.length > 10) refs.push(r);
      cur = "";
    }

    for (const raw of lines){
      let l = normalizeRefLine(raw);
      if (!l) continue;

      // join arXiv lines to previous ref
      if (isArxivOnly(l) && cur){
        cur += (cur ? " " : "") + l;
        continue;
      }

      if (isNew(raw)){
        pushCur();
        // keep label like [AB24] (do NOT remove), but still normalize spacing
        cur = raw.replace(/\s+/g," ").trim();
      } else {
        cur += (cur ? " " : "") + l;
      }

      if (refs.length >= 500) break;
    }
    pushCur();

    // de-dup
    const seen = new Set();
    const uniq = [];
    for (const r of refs){
      const k = r.toLowerCase();
      if (!seen.has(k)){ seen.add(k); uniq.push(r); }
    }

    // drop micro-garbage refs like ":4033–4078," if it slipped through
    return uniq.filter(r => r.replace(/[^a-z0-9]/ig,"").length >= 12);
  }

  // ----------------------------
  // Affiliations (scan end pages + find "Affiliations" block)
  // ----------------------------
  function looksLikeAffLine(l){
    const s = (l||"").trim();
    if (s.length < 10) return false;
    // typical: "Name, University..., Orcid ID ..."
    return /,/.test(s) && /(university|institute|department|dept\.|school|faculty|laboratory|centre|center|hospital|college|cnrs|inria|inaf|infn|observator|orcid)/i.test(s);
  }

  function parseAffiliationsSectionFromText(pageText){
    if (!pageText) return [];
    const lines = pageText.replace(/\r/g,"\n").split("\n").map(l=>l.trim()).filter(Boolean);
    const idx = lines.findIndex(l => /^\s*\d*\.\s*affiliations\b/i.test(l) || /^\s*affiliations\b/i.test(l));
    if (idx < 0) return [];

    const out = [];
    for (let i=idx+1;i<lines.length;i++){
      const l = lines[i];
      if (/^\s*(references|bibliography)\b/i.test(l)) break;
      // stop at next numbered section
      if (/^\s*\d+\.\s+[A-Za-z]/.test(l) && i > idx+1) break;

      if (looksLikeAffLine(l)) out.push(l);
      // allow wrapped affiliation lines: if next line continues and current ends with comma
      else if (out.length && /,$/.test(out[out.length-1]) && l.length < 140) {
        out[out.length-1] = (out[out.length-1] + " " + l).replace(/\s+/g," ").trim();
      }
    }
    return out.slice(0, 80);
  }

  function nameToKey(name){
    return String(name||"").toLowerCase().replace(/[^a-z0-9\s\-]/g,"").replace(/\s+/g," ").trim();
  }

  function matchAffLineToAuthor(affLine, authors){
    // affLine example: "Emilia Alvarez, University of Bristol, Orcid ID ..."
    const first = String(affLine||"").split(",")[0].trim();
    const key = nameToKey(first);

    // try surname match first
    for (const a of authors){
      const sur = nameToKey(a.surname || a.keyname || "");
      if (sur && key.endsWith(" " + sur) || key === sur) return a;
    }
    // fallback: any word overlap with full name
    for (const a of authors){
      const full = nameToKey(`${a.given||a.forenames||""} ${a.surname||a.keyname||""}`);
      if (!full) continue;
      if (full && (key.includes(full) || full.includes(key))) return a;
    }
    return null;
  }

  // ----------------------------
  // Build Elsevier XML (NO EMPTY TAGS)
  // ----------------------------
  function buildElsevierXml({ arxivIdWithVersion, chosenTitle, abstractText, keywords, authors, references }) {
    const nowIso = new Date().toISOString();

    const kwXml = (keywords?.length)
      ? `<author-keywords>\n${keywords.map(k => `              <author-keyword>${escapeXml(k)}</author-keyword>`).join("\n")}\n            </author-keywords>\n`
      : "";

    const authorGroupsXml = (authors || []).map((a, i) => {
      const given = (a.given || a.forenames || "").trim();
      const surname = (a.surname || a.keyname || "").trim();
      const initials = (a.initials || makeInitials(given) || "").trim();

      // Build author tag with optional orcid attribute? (You used nested in examples, but arXiv API varies)
      const email = (a.email || (a.emails && a.emails[0]) || "").trim();
      const orcid = (a.orcid || "").trim();
      const degrees = (a.degrees || []).filter(Boolean);

      const degXml = degrees.length ? `\n              <ce:degrees>${escapeXml(degrees.join(" "))}</ce:degrees>` : "";
      const emailXml = email ? `\n              <ce:e-address>${escapeXml(email)}</ce:e-address>` : "";

      // affiliations: only if present (NO empty tags)
      const affs = (a.affiliations || []).map(x => String(x||"").trim()).filter(Boolean).slice(0, 10);
      const affXml = affs.length
        ? affs.map(src => `            <affiliation>
              <ce:source-text>${escapeXml(src)}</ce:source-text>
            </affiliation>`).join("\n")
        : "";

      const orcidAttr = orcid ? ` orcid="${escapeXml(orcid)}"` : "";

      return `          <author-group seq="${i+1}">
            <author seq="${i+1}"${orcidAttr}>
              <ce:initials>${escapeXml(initials)}</ce:initials>${degXml}
              <ce:surname>${escapeXml(surname)}</ce:surname>
              <ce:given-name>${escapeXml(given)}</ce:given-name>${emailXml}
            </author>
${affXml ? affXml + "\n" : ""}          </author-group>`;
    }).join("\n");

    const absXml = abstractText
      ? `          <abstracts>
            <abstract original="y" xml:lang="ENG">
              <ce:para>${applySupSubXml(abstractText)}</ce:para>
            </abstract>
          </abstracts>\n`
      : "";

    const refs = references || [];
    const refsXml = refs.length
      ? `<bibliography refcount="${refs.length}">
${refs.map((r, idx) => `          <reference seq="${idx+1}">
            <ref-info/>
            <ref-fulltext>${escapeXml(r)}</ref-fulltext>
            <ce:source-text>${escapeXml(r)}</ce:source-text>
          </reference>`).join("\n")}
        </bibliography>`
      : `<bibliography refcount="0"/>`;

    return `<?xml version="1.0" encoding="utf-8"?>
<units xmlns="http://www.elsevier.com/xml/ani/ani" xmlns:ce="http://www.elsevier.com/xml/ani/common">
  <unit type="ARTICLE">
    <unit-info>
      <unit-id>1</unit-id>
      <order-id>unknown</order-id>
      <parcel-id>none</parcel-id>
      <supplier-id>4</supplier-id>
      <timestamp>${escapeXml(nowIso)}</timestamp>
    </unit-info>
    <unit-content>
      <bibrecord>
        <item-info>
          <status state="new"/>
          <itemidlist>
            <itemid idtype="ARXIV">${escapeXml(arxivIdWithVersion)}</itemid>
          </itemidlist>
        </item-info>
        <head>
          <citation-info>
            <citation-type code="ar"/>
            <citation-language xml:lang="ENG"/>
            <abstract-language xml:lang="ENG"/>
${kwXml}          </citation-info>
          <citation-title>
            <titletext xml:lang="ENG" original="y">${escapeXml(chosenTitle)}</titletext>
          </citation-title>
${authorGroupsXml || `          <author-group seq="1">
            <author seq="1">
              <ce:initials></ce:initials>
              <ce:surname></ce:surname>
              <ce:given-name></ce:given-name>
            </author>
          </author-group>`}
${absXml}          <source srcid="???"/>
        </head>
        <tail>
          ${refsXml}
        </tail>
      </bibrecord>
    </unit-content>
  </unit>
</units>`;
  }

  // ----------------------------
  // Support-doc detection (BY CONTENT)
  // ----------------------------
  async function detectSupportDocsByContent(zip, guessedId) {
    const names = Object.keys(zip.files).filter(n => !zip.files[n].dir);

    const xmlNames = names.filter(n => lower(n).endsWith(".xml"));
    const htmlNames = names.filter(n => lower(n).endsWith(".html") || lower(n).endsWith(".htm"));

    let apiName = null;
    let scrapeName = null;

    for (const n of xmlNames) {
      const txt = await zip.file(n).async("string");
      const head = txt.slice(0, 9000).toLowerCase();

      const looksApi =
        head.includes("<record") ||
        head.includes("oai:arxiv.org:") ||
        head.includes("<arxiv") ||
        head.includes("<metadata");

      const looksScrape =
        head.includes("<item") && head.includes("version") && head.includes("[v");

      if (!apiName && looksApi) apiName = n;
      if (!scrapeName && looksScrape) scrapeName = n;
    }

    if (guessedId) {
      const apiByName = xmlNames.find(n => n.includes(guessedId) && n !== scrapeName);
      if (apiByName) apiName = apiByName;

      const scrapeByName = xmlNames.find(n => n.includes(guessedId) && n !== apiName);
      if (scrapeByName && !scrapeName) scrapeName = scrapeByName;
    }

    const htmlName = (guessedId
      ? (htmlNames.find(n => n.includes(guessedId)) || htmlNames[0] || null)
      : (htmlNames[0] || null)
    );

    return { apiName, scrapeName, htmlName };
  }

  // ----------------------------
  // ZIP Load
  // ----------------------------
  zipInput.addEventListener("change", async (e) => {
    const file = e.target.files?.[0];
    if (!file) return;

    resetAll();
    zipBadge.className = "badge warn";
    zipBadge.textContent = "Loading ZIP…";

    try {
      const buf = await file.arrayBuffer();
      const zip = await JSZip.loadAsync(buf);
      state.zip = zip;

      state.fileNames = Object.keys(zip.files).filter(n => !zip.files[n].dir);
      state.pdfs = state.fileNames.filter(n => lower(n).endsWith(".pdf"));

      fileCount.textContent = String(state.pdfs.length);
      zipBadge.className = "badge good";
      zipBadge.textContent = `ZIP loaded: ${file.name}`;

      renderPdfList();
      if (state.pdfs.length) selectPdf(0);

    } catch (err) {
      console.error(err);
      zipBadge.className = "badge bad";
      zipBadge.textContent = "Failed to read ZIP";
    }
  });

  function resetAll(){
    state.fileNames = [];
    state.pdfs = [];
    state.selectedPdf = null;
    state.selected = { pdfName:null, apiName:null, scrapeName:null, htmlName:null };

    apiText.value = "";
    scrapeText.value = "";
    htmlPreview.innerHTML = "No HTML loaded.";
    outXml.value = "";

    downloadBtn.disabled = true;
    runBtn.disabled = true;

    pdfIdVal.textContent = "—";
    pdfVerVal.textContent = "—";
    htmlIdVal.textContent = "—";
    htmlVerVal.textContent = "—";
    scrIdVal.textContent = "—";
    scrVerVal.textContent = "—";

    titleCheckVal.innerHTML = "—";
    matchVal.innerHTML = "—";
    titleVal.textContent = "—";
    absVal.innerHTML = "—";
    kwVal.innerHTML = "—";
    authVal.innerHTML = "—";
    affVal.innerHTML = "—";
    refVal.innerHTML = "—";

    selectedSet.textContent = "No set selected";
    state.pdfTextByPage = new Map();

    clearPdf();
    fileList.innerHTML = "";
    fileCount.textContent = "0";
  }

  // ----------------------------
  // Render PDF list
  // ----------------------------
  function renderPdfList(){
    fileList.innerHTML = "";
    state.pdfs.forEach((pdfName, idx) => {
      const div = document.createElement("div");
      div.className = "item" + (idx === state.selectedPdf ? " active" : "");
      const idGuess = extractArxivFromText(pdfName).id || "PDF";
      div.innerHTML = `
        <div style="display:flex;align-items:center;justify-content:space-between;gap:8px">
          <div style="font-weight:900;font-size:13px">${escapeHtml(pdfName.split("/").pop())}</div>
          <span class="badge">${escapeHtml(idGuess)}</span>
        </div>
        <div class="muted" style="margin-top:6px">Auto-detects API/Scrape/HTML by file content.</div>
      `;
      div.addEventListener("click", () => selectPdf(idx));
      fileList.appendChild(div);
    });
  }

  async function selectPdf(idx){
    state.selectedPdf = idx;
    renderPdfList();

    const pdfName = state.pdfs[idx];
    selectedSet.textContent = `Selected: ${pdfName.split("/").pop()}`;

    const { id: guessedId } = extractArxivFromText(pdfName);
    const support = await detectSupportDocsByContent(state.zip, guessedId);

    state.selected = {
      pdfName,
      apiName: support.apiName,
      scrapeName: support.scrapeName,
      htmlName: support.htmlName
    };

    runBtn.disabled = false;

    await loadPdfFromZip(pdfName);
    await loadTextPreview(state.selected.apiName, apiText);
    await loadTextPreview(state.selected.scrapeName, scrapeText);
    await loadHtmlPreview(state.selected.htmlName);
  }

  async function loadTextPreview(name, targetTextarea){
    if (!name) { targetTextarea.value = ""; return; }
    const file = state.zip.file(name);
    if (!file) { targetTextarea.value = ""; return; }
    targetTextarea.value = await file.async("string");
  }

  async function loadHtmlPreview(name){
    if (!name) { htmlPreview.innerHTML = "No HTML loaded."; return; }
    const file = state.zip.file(name);
    if (!file) { htmlPreview.innerHTML = "No HTML loaded."; return; }
    const txt = await file.async("string");
    htmlPreview.innerHTML = stripScripts(txt) || "No HTML content.";
  }

  // ----------------------------
  // PDF preview
  // ----------------------------
  function clearPdf(){
    state.pdfDoc = null;
    state.pdfPageNum = 1;
    state.pdfPageCount = 0;
    pageInfo.textContent = "- / -";
    prevPageBtn.disabled = true;
    nextPageBtn.disabled = true;
    const ctx = pdfCanvas.getContext("2d");
    ctx.clearRect(0,0,pdfCanvas.width,pdfCanvas.height);
  }

  async function loadPdfFromZip(name){
    clearPdf();
    state.pdfTextByPage = new Map();
    const file = state.zip.file(name);
    if (!file) return;

    const u8 = await file.async("uint8array");
    const loadingTask = pdfjsLib.getDocument({ data: u8 });
    const pdf = await loadingTask.promise;

    state.pdfDoc = pdf;
    state.pdfPageCount = pdf.numPages;
    state.pdfPageNum = 1;

    await renderPdfPage(1);
  }

  async function renderPdfPage(num){
    if (!state.pdfDoc) return;
    const page = await state.pdfDoc.getPage(num);
    const viewport = page.getViewport({ scale: 1.3 });
    const ctx = pdfCanvas.getContext("2d");
    pdfCanvas.width = viewport.width;
    pdfCanvas.height = viewport.height;

    await page.render({ canvasContext: ctx, viewport }).promise;

    pageInfo.textContent = `${num} / ${state.pdfPageCount}`;
    prevPageBtn.disabled = (num <= 1);
    nextPageBtn.disabled = (num >= state.pdfPageCount);
  }

  prevPageBtn.addEventListener("click", async () => {
    if (!state.pdfDoc || state.pdfPageNum <= 1) return;
    state.pdfPageNum -= 1;
    await renderPdfPage(state.pdfPageNum);
  });

  nextPageBtn.addEventListener("click", async () => {
    if (!state.pdfDoc || state.pdfPageNum >= state.pdfPageCount) return;
    state.pdfPageNum += 1;
    await renderPdfPage(state.pdfPageNum);
  });

  async function getPdfPageText(pageNum){
    if (state.pdfTextByPage.has(pageNum)) return state.pdfTextByPage.get(pageNum);
    const page = await state.pdfDoc.getPage(pageNum);
    const txt = await page.getTextContent();
    const text = txt.items.map(it => it.str || "").join("\n");
    state.pdfTextByPage.set(pageNum, text);
    return text;
  }

  async function getPdfAllTextLimited(){
    const total = state.pdfPageCount || 0;
    let out = "";
    for (let p=1;p<=total;p++){
      const t = await getPdfPageText(p);
      out += "\n" + t;
      if (out.length > 420000) break;
    }
    return out;
  }

  function guessPdfTitleFromFirstPage(p1){
    if (!p1) return "";
    const lines = p1.replace(/\r/g,"\n").split("\n").map(x=>x.trim()).filter(Boolean);
    const filtered = lines.filter(l => !/arxiv:\d{4}\.\d{4,5}/i.test(l));
    const head = filtered.slice(0, 30);
    let best = "";
    for (const l of head){
      if (l.length > best.length) best = l;
    }
    return best.trim();
  }

  // ----------------------------
  // Strict validation logic
  // ----------------------------
  function isFullIdVer(x){ return !!(x?.id && x?.version); }
  function idVerEqual(a,b){
    return normId(a?.id) === normId(b?.id) && normVer(a?.version) === normVer(b?.version);
  }

  // ----------------------------
  // Run Extraction
  // ----------------------------
  runBtn.addEventListener("click", async () => {
    try {
      if (!state.selected?.pdfName || !state.pdfDoc) return;

      const apiRaw = apiText.value || "";
      const scrapeRaw = scrapeText.value || "";
      const htmlRaw = state.selected.htmlName ? await state.zip.file(state.selected.htmlName).async("string") : "";

      const api = apiRaw ? parseApiXml(apiRaw) : null;
      const scrape = scrapeRaw ? parseScrapeXml(scrapeRaw) : null;
      const html = htmlRaw ? parseHtmlLanding(htmlRaw) : null;

      // PDF ID/version from page 1
      const p1 = await getPdfPageText(1);
      const pdfIdVer = extractArxivFromText(p1);
      const pdfHasId = !!pdfIdVer.id;
      const pdfHasVer = !!pdfIdVer.version;

      const htmlIdVer = { id: (html?.id||""), version: (html?.version||"") };
      const scrIdVer  = { id: (scrape?.id||""), version: (scrape?.version||"") };

      pdfIdVal.textContent = pdfIdVer.id || "—";
      pdfVerVal.textContent = pdfIdVer.version || "—";
      htmlIdVal.textContent = htmlIdVer.id || "—";
      htmlVerVal.textContent = htmlIdVer.version || "—";
      scrIdVal.textContent  = scrIdVer.id || "—";
      scrVerVal.textContent = scrIdVer.version || "—";

      const pdfTitleGuess = guessPdfTitleFromFirstPage(p1);
      const htmlTitle = (html?.title||"").trim();

      const titleSame = titlesExactlySame(pdfTitleGuess, htmlTitle);
      titleCheckVal.innerHTML = titleSame ? badge("OK – same (strict)", "good") : badge("HOLD – mismatch", "bad");

      // STRICT validation per your rule set
      let holdReason = "";
      let okToProcess = false;

      if (pdfHasId) {
        if (!pdfHasVer) {
          holdReason = "PDF has ID but no version → HOLD (need version consistency).";
          okToProcess = false;
        } else {
          const pdf = { id: pdfIdVer.id, version: pdfIdVer.version };
          const htmlOk = isFullIdVer(htmlIdVer);
          const scrOk  = isFullIdVer(scrIdVer);

          if (!htmlOk || !scrOk) {
            holdReason = "Missing ID/version on HTML or Scrape.";
            okToProcess = false;
          } else if (idVerEqual(pdf, htmlIdVer) && idVerEqual(pdf, scrIdVer) && idVerEqual(htmlIdVer, scrIdVer)) {
            okToProcess = true;
          } else {
            holdReason = "ID/version mismatch across PDF/HTML/Scrape.";
            okToProcess = false;
          }
        }
      } else {
        if (!titleSame) {
          holdReason = "PDF has no ID → Title mismatch (strict) → HOLD.";
          okToProcess = false;
        } else {
          const htmlOk = isFullIdVer(htmlIdVer);
          const scrOk  = isFullIdVer(scrIdVer);
          if (!htmlOk || !scrOk) {
            holdReason = "PDF has no ID → Title matches, but missing HTML/Scrape ID+version.";
            okToProcess = false;
          } else if (idVerEqual(htmlIdVer, scrIdVer)) {
            okToProcess = true;
          } else {
            holdReason = "PDF has no ID → Title matches, but HTML vs Scrape ID/version mismatch.";
            okToProcess = false;
          }
        }
      }

      matchVal.innerHTML = okToProcess
        ? badge("OK – PROCESS", "good")
        : badge("HOLD – DO NOT PROCESS", "bad");

      if (!okToProcess) {
        titleVal.textContent = chooseTitle(pdfTitleGuess, htmlTitle) || "—";
        absVal.innerHTML = badge("—", "warn");
        kwVal.innerHTML = badge("—", "warn");
        authVal.innerHTML = badge("—", "warn");
        affVal.innerHTML = badge("—", "warn");
        refVal.innerHTML = badge("—", "warn");
        outXml.value = `HOLD\nReason: ${holdReason}\n\nDetected:\nPDF: ${pdfIdVer.id||"—"}${pdfIdVer.version||""}\nHTML: ${htmlIdVer.id||"—"}${htmlIdVer.version||""}\nSCRAPE: ${scrIdVer.id||"—"}${scrIdVer.version||""}\n\nPDF Title Guess:\n${pdfTitleGuess}\n\nHTML Title:\n${htmlTitle}`;
        downloadBtn.disabled = true;
        return;
      }

      const finalId = pdfHasId ? pdfIdVer.id : htmlIdVer.id;
      const finalVer = pdfHasId ? pdfIdVer.version : htmlIdVer.version;
      const arxivIdWithVersion = `${finalId}${finalVer}`;

      const chosenTitle = chooseTitle(pdfTitleGuess, htmlTitle);

      const absText = stripTeXMath((api?.abstract || html?.abstract || "").trim());

      // STRICT KEYWORDS: only if explicit "Keywords:" line exists
      const pdfAllText = await getPdfAllTextLimited();
      const kw = extractKeywordsStrictFromPdfText(pdfAllText);

      // Authors: from API
      const authors = (api?.authors || []).map(a => ({
        ...a,
        affiliations: Array.isArray(a.affiliations) ? a.affiliations : []
      }));

      // AFFILIATIONS: scan last pages for "Affiliations" section and link by author name
      const affLinkedCount = await linkAffiliationsFromPdf(authors);

      // REFERENCES: better splitting + remove numbering
      const refs = extractReferencesFromPdfTextBetter(pdfAllText);

      titleVal.textContent = chosenTitle || "—";
      absVal.innerHTML = absText ? badge("Yes", "good") : badge("No", "warn");
      kwVal.innerHTML = kw.length ? badge(`${kw.length} keyword(s)`, "good") : badge("None", "warn");
      authVal.innerHTML = authors.length ? badge(`API authors: ${authors.length}`, "good") : badge("No authors", "warn");
      affVal.innerHTML = affLinkedCount ? badge(`${affLinkedCount} linked`, "good") : badge("None linked", "warn");
      refVal.innerHTML = refs.length ? badge(`${refs.length} ref(s)`, "good") : badge("0", "warn");

      const xml = buildElsevierXml({
        arxivIdWithVersion,
        chosenTitle,
        abstractText: absText,
        keywords: kw,
        authors,
        references: refs
      });

      outXml.value = xml;
      downloadBtn.disabled = !xml;

    } catch (e) {
      console.error(e);
      alert("Extraction failed. Open DevTools Console and send me the red error line.");
    }
  });

  async function linkAffiliationsFromPdf(authors){
    const total = state.pdfPageCount || 0;
    if (!total || !authors?.length) return 0;

    // Quick scan: last 8 pages backwards to find "Affiliations" heading
    const maxBack = Math.min(10, total);
    let affLines = [];
    let foundOnPage = -1;

    for (let k=0;k<maxBack;k++){
      const p = total - k;
      const t = await getPdfPageText(p);
      const lines = parseAffiliationsSectionFromText(t);
      if (lines.length){
        affLines = lines;
        foundOnPage = p;
        break;
      }
    }

    // If not found at extreme end, try last-12..last-25 (some papers have refs last page)
    if (!affLines.length && total > 12){
      for (let p=Math.max(1, total-25); p<=total-10; p++){
        const t = await getPdfPageText(p);
        const lines = parseAffiliationsSectionFromText(t);
        if (lines.length){
          affLines = lines;
          foundOnPage = p;
          break;
        }
      }
    }

    // If still not found: do nothing (no assumptions)
    if (!affLines.length) return 0;

    let linked = 0;
    for (const line of affLines){
      const a = matchAffLineToAuthor(line, authors);
      if (!a) continue;
      // affiliation source text = everything after first comma
      const parts = String(line).split(",");
      if (parts.length < 2) continue;
      const src = parts.slice(1).join(",").replace(/\s+/g," ").trim();
      if (!src) continue;

      if (!Array.isArray(a.affiliations)) a.affiliations = [];
      // avoid duplicates
      const exists = a.affiliations.some(x => String(x).toLowerCase() === src.toLowerCase());
      if (!exists){
        a.affiliations.push(src);
        linked++;
      }
    }

    return linked;
  }

  // ----------------------------
  // Download
  // ----------------------------
  downloadBtn.addEventListener("click", () => {
    const xml = outXml.value;
    if (!xml || xml.startsWith("HOLD")) return;
    const blob = new Blob([xml], { type: "application/xml;charset=utf-8" });
    const a = document.createElement("a");
    a.href = URL.createObjectURL(blob);
    a.download = `ACE_${Date.now()}_arxiv.xml`;
    document.body.appendChild(a);
    a.click();
    a.remove();
  });
</script>
</body>
</html>
