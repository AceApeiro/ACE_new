<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>ACE – Zip Extractor (arXiv)</title>

  <!-- JSZip -->
  <script src="https://cdn.jsdelivr.net/npm/jszip@3.10.1/dist/jszip.min.js"></script>

  <!-- PDF.js -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>

  <style>
    :root{
      --bg:#0b0f14; --panel:#111827; --panel2:#0f172a; --muted:#94a3b8;
      --text:#e5e7eb; --good:#22c55e; --bad:#ef4444; --warn:#f59e0b; --line:#1f2937;
      --btn:#2563eb; --btn2:#334155;
    }
    *{box-sizing:border-box}
    body{margin:0; font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Arial; background:var(--bg); color:var(--text)}
    .wrap{max-width:1400px; margin:0 auto; padding:14px}
    .top{display:flex; gap:10px; align-items:center; flex-wrap:wrap}
    .card{background:linear-gradient(180deg,var(--panel),var(--panel2)); border:1px solid var(--line); border-radius:14px; padding:12px}
    .grow{flex:1}
    .row{display:flex; gap:12px; margin-top:12px}
    .colL{width:320px; min-width:280px}
    .colR{flex:1; min-width:320px}
    .h{display:flex; align-items:center; justify-content:space-between; gap:10px; margin-bottom:8px}
    .title{font-size:14px; font-weight:700}
    .muted{color:var(--muted); font-size:12px}
    .btn{border:0; background:var(--btn); color:white; padding:10px 12px; border-radius:10px; cursor:pointer; font-weight:700}
    .btn.secondary{background:var(--btn2)}
    .btn:disabled{opacity:.5; cursor:not-allowed}
    input[type="file"]{display:none}
    .fileLabel{display:inline-flex; gap:10px; align-items:center; border:1px dashed #334155; padding:10px 12px; border-radius:12px; cursor:pointer}
    .list{max-height:420px; overflow:auto; border-top:1px solid var(--line); margin-top:10px; padding-top:10px}
    .item{padding:10px; border:1px solid var(--line); border-radius:12px; margin-bottom:8px; cursor:pointer; background:#0b1220}
    .item.active{outline:2px solid #2563eb}
    .badge{font-size:11px; padding:3px 8px; border-radius:999px; border:1px solid var(--line); background:#0b1220}
    .badge.good{border-color:rgba(34,197,94,.6); color:var(--good)}
    .badge.bad{border-color:rgba(239,68,68,.6); color:var(--bad)}
    .badge.warn{border-color:rgba(245,158,11,.6); color:var(--warn)}
    .grid{display:grid; grid-template-columns: 1.35fr .65fr; gap:12px}
    .tabs{display:flex; gap:8px; flex-wrap:wrap}
    .tab{padding:8px 10px; border-radius:10px; border:1px solid var(--line); background:#0b1220; cursor:pointer; font-weight:700; font-size:12px}
    .tab.active{border-color:#2563eb}
    .pane{display:none}
    .pane.active{display:block}
    .box{border:1px solid var(--line); border-radius:12px; overflow:hidden; background:#050a12}
    .boxHead{padding:8px 10px; border-bottom:1px solid var(--line); display:flex; align-items:center; justify-content:space-between}
    .boxBody{padding:10px}
    textarea{width:100%; min-height:220px; background:#050a12; color:var(--text); border:1px solid var(--line); border-radius:12px; padding:10px; font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace; font-size:12px}
    .kv{display:grid; grid-template-columns: 160px 1fr; gap:8px; font-size:13px}
    .k{color:var(--muted)}
    .statusLine{display:flex; gap:8px; flex-wrap:wrap; align-items:center}
    canvas{width:100%; height:auto; background:#0b1220; border-radius:10px}
    .htmlPreview{max-height:520px; overflow:auto; background:white; color:black; border-radius:10px; padding:10px}
    .small{font-size:12px}
    .hr{height:1px; background:var(--line); margin:10px 0}
    .mono{font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace}
  </style>
</head>

<body>
<div class="wrap">

  <div class="top card">
    <div class="grow">
      <div style="display:flex;align-items:center;justify-content:space-between;gap:10px;flex-wrap:wrap">
        <div>
          <div style="font-size:16px;font-weight:900;letter-spacing:.2px">ACE – Apeiro Citation Extractor (arXiv ZIP)</div>
          <div class="muted">Upload a ZIP containing PDF + API XML + Scraping XML + HTML summary. Validate arXiv ID/version, validate title if PDF has no ID, generate strict Elsevier XML.</div>
        </div>

        <div style="display:flex;gap:10px;align-items:center;flex-wrap:wrap">
          <label class="fileLabel">
            <span class="badge">ZIP</span>
            <span class="small">Choose ZIP</span>
            <input id="zipInput" type="file" accept=".zip" />
          </label>

          <button id="runBtn" class="btn" disabled>Run Extraction</button>
          <button id="downloadBtn" class="btn secondary" disabled>Download XML</button>
        </div>
      </div>

      <div class="hr"></div>

      <div class="statusLine">
        <span class="badge" id="zipBadge">No ZIP loaded</span>
        <span class="muted" id="hint">Tip: open DevTools Console if something doesn’t load.</span>
      </div>
    </div>
  </div>

  <div class="row">
    <!-- LEFT -->
    <div class="colL card">
      <div class="h">
        <div class="title">PDFs in ZIP</div>
        <div class="muted" id="fileCount">0</div>
      </div>

      <div class="muted">Select a PDF. ACE auto-pairs support docs by reading their content.</div>
      <div class="list" id="fileList"></div>
    </div>

    <!-- RIGHT -->
    <div class="colR">
      <div class="grid">

        <!-- PREVIEW -->
        <div class="card">
          <div class="h">
            <div class="title">Preview</div>
            <div class="tabs">
              <div class="tab active" data-tab="pdfPane">PDF</div>
              <div class="tab" data-tab="htmlPane">HTML Summary</div>
              <div class="tab" data-tab="apiPane">API XML</div>
              <div class="tab" data-tab="scrapePane">Scrape XML</div>
            </div>
          </div>

          <div id="pdfPane" class="pane active">
            <div class="box">
              <div class="boxHead">
                <div class="small muted">PDF rendered via PDF.js</div>
                <div style="display:flex;gap:8px;align-items:center">
                  <button class="btn secondary" id="prevPageBtn" disabled>Prev</button>
                  <span class="badge mono" id="pageInfo">- / -</span>
                  <button class="btn secondary" id="nextPageBtn" disabled>Next</button>
                </div>
              </div>
              <div class="boxBody">
                <canvas id="pdfCanvas"></canvas>
              </div>
            </div>
          </div>

          <div id="htmlPane" class="pane">
            <div class="box">
              <div class="boxHead">
                <div class="small muted">HTML is sanitized (scripts removed).</div>
              </div>
              <div class="boxBody">
                <div id="htmlPreview" class="htmlPreview">No HTML loaded.</div>
              </div>
            </div>
          </div>

          <div id="apiPane" class="pane">
            <textarea id="apiText" readonly placeholder="API XML preview..."></textarea>
          </div>

          <div id="scrapePane" class="pane">
            <textarea id="scrapeText" readonly placeholder="Scrape XML preview..."></textarea>
          </div>
        </div>

        <!-- EXTRACTION -->
        <div class="card">
          <div class="h">
            <div class="title">Extraction</div>
            <span class="badge" id="selectedSet">No set selected</span>
          </div>

          <div class="box">
            <div class="boxHead">
              <div class="small muted">Validation checks (conditional-formatting logic)</div>
            </div>
            <div class="boxBody">
              <div class="kv">
                <div class="k">PDF arXiv ID</div><div class="mono" id="pdfIdVal">—</div>
                <div class="k">HTML arXiv ID</div><div class="mono" id="htmlIdVal">—</div>
                <div class="k">Scrape arXiv ID</div><div class="mono" id="scrapeIdVal">—</div>

                <div class="k">PDF version</div><div class="mono" id="pdfVerVal">—</div>
                <div class="k">HTML version</div><div class="mono" id="htmlVerVal">—</div>
                <div class="k">Scrape version</div><div class="mono" id="scrapeVerVal">—</div>

                <div class="k">Title (PDF)</div><div id="pdfTitleVal">—</div>
                <div class="k">Title (HTML)</div><div id="htmlTitleVal">—</div>

                <div class="k">PROCESS / HOLD</div><div id="matchVal">—</div>

                <div class="k">Chosen title</div><div id="titleVal">—</div>
                <div class="k">Abstract found?</div><div id="absVal">—</div>
                <div class="k">Keywords found?</div><div id="kwVal">—</div>
                <div class="k">Authors found?</div><div id="authVal">—</div>
                <div class="k">Affiliations found?</div><div id="affVal">—</div>
                <div class="k">References found?</div><div id="refVal">—</div>
              </div>
            </div>
          </div>

          <div class="hr"></div>

          <div class="title" style="margin-bottom:8px">Generated XML (strict structure)</div>
          <textarea id="outXml" placeholder="Run Extraction to generate XML..." spellcheck="false"></textarea>
        </div>

      </div>
    </div>
  </div>
</div>

<script>
  // --- PDF.js worker ---
  pdfjsLib.GlobalWorkerOptions.workerSrc =
    "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";

  // ----------------------------
  // State
  // ----------------------------
  const state = {
    zip: null,
    fileNames: [],
    pdfs: [],
    selectedPdf: null,
    selected: { pdfName:null, apiName:null, scrapeName:null, htmlName:null, finalName:null },
    pdfDoc: null,
    pdfPageNum: 1,
    pdfPageCount: 0,
    pdfTextByPage: [],
    pdfAllText: ""
  };

  // ----------------------------
  // UI refs
  // ----------------------------
  const zipInput = document.getElementById("zipInput");
  const runBtn = document.getElementById("runBtn");
  const downloadBtn = document.getElementById("downloadBtn");

  const zipBadge = document.getElementById("zipBadge");
  const fileCount = document.getElementById("fileCount");
  const fileList = document.getElementById("fileList");
  const selectedSet = document.getElementById("selectedSet");

  const apiText = document.getElementById("apiText");
  const scrapeText = document.getElementById("scrapeText");
  const htmlPreview = document.getElementById("htmlPreview");

  const pdfIdVal = document.getElementById("pdfIdVal");
  const htmlIdVal = document.getElementById("htmlIdVal");
  const scrapeIdVal = document.getElementById("scrapeIdVal");
  const pdfVerVal = document.getElementById("pdfVerVal");
  const htmlVerVal = document.getElementById("htmlVerVal");
  const scrapeVerVal = document.getElementById("scrapeVerVal");
  const pdfTitleVal = document.getElementById("pdfTitleVal");
  const htmlTitleVal = document.getElementById("htmlTitleVal");

  const matchVal = document.getElementById("matchVal");
  const titleVal = document.getElementById("titleVal");
  const absVal = document.getElementById("absVal");
  const kwVal = document.getElementById("kwVal");
  const authVal = document.getElementById("authVal");
  const affVal = document.getElementById("affVal");
  const refVal = document.getElementById("refVal");

  const outXml = document.getElementById("outXml");

  const pdfCanvas = document.getElementById("pdfCanvas");
  const prevPageBtn = document.getElementById("prevPageBtn");
  const nextPageBtn = document.getElementById("nextPageBtn");
  const pageInfo = document.getElementById("pageInfo");

  // Tabs
  document.querySelectorAll(".tab").forEach(t => {
    t.addEventListener("click", () => {
      document.querySelectorAll(".tab").forEach(x => x.classList.remove("active"));
      document.querySelectorAll(".pane").forEach(p => p.classList.remove("active"));
      t.classList.add("active");
      document.getElementById(t.dataset.tab).classList.add("active");
    });
  });

  // ----------------------------
  // Helpers
  // ----------------------------
  const lower = s => (s || "").toLowerCase();

  function escapeHtml(s) {
    return String(s ?? "").replace(/[&<>"']/g, c => ({
      "&":"&amp;","<":"&lt;",">":"&gt;",'"':"&quot;","'":"&#039;"
    }[c]));
  }

  function badge(text, kind="") {
    const cls = kind ? `badge ${kind}` : "badge";
    return `<span class="${cls}">${escapeHtml(text)}</span>`;
  }

  function stripScripts(html) {
    const doc = new DOMParser().parseFromString(html, "text/html");
    doc.querySelectorAll("script, iframe, object, embed").forEach(n => n.remove());
    doc.querySelectorAll("*").forEach(el => {
      [...el.attributes].forEach(a => {
        if (a.name.startsWith("on")) el.removeAttribute(a.name);
      });
    });
    return doc.body.innerHTML || "";
  }

  // arXiv ID formats we care about
  // - 2409.10724
  // - arXiv:2409.10724v4
  const ARXIV_NUM_RE = /(\d{4}\.\d{4,5})(v\d+)?/i;

  function extractArxivFromText(text) {
    if (!text) return { id:null, version:null };

    // Most reliable: arXiv:NNNN.NNNNNvN
    const m1 = /arxiv:\s*(\d{4}\.\d{4,5})(v\d+)?/i.exec(text);
    if (m1) return { id: m1[1], version: (m1[2]||null) };

    // OAI
    const m2 = /oai:arxiv\.org:(\d{4}\.\d{4,5})/i.exec(text);
    if (m2) return { id: m2[1], version: null };

    // Any bare numeric id
    const m3 = ARXIV_NUM_RE.exec(text);
    if (m3) return { id: m3[1], version: (m3[2]||null) };

    return { id:null, version:null };
  }

  // HTML "Cite as" second line rule:
  // "Cite as: arXiv:2409.10724 [..] (or arXiv:2409.10724v4 [..] for this version)"
  function extractArxivFromHtmlCiteAs(htmlStr) {
    try {
      const doc = new DOMParser().parseFromString(htmlStr, "text/html");
      const txt = (doc.body?.textContent || "").replace(/\s+/g, " ").trim();

      // Prefer the "(or arXiv:XXXX.XXXXXvN ...)" version line if present
      const mOr = /\(or\s+arxiv:\s*(\d{4}\.\d{4,5})(v\d+)\b/i.exec(txt);
      if (mOr) return { id: mOr[1], version: mOr[2] };

      // Else fall back to any arXiv:XXXX.XXXXXvN
      const mA = /arxiv:\s*(\d{4}\.\d{4,5})(v\d+)?/i.exec(txt);
      if (mA) return { id: mA[1], version: (mA[2] || null) };

      // Else fallback to numeric
      return extractArxivFromText(txt);
    } catch {
      return extractArxivFromText(htmlStr);
    }
  }

  // --- XML helpers ---
  function xmlText(node, tagName) {
    const el = node.getElementsByTagName(tagName)[0];
    return el ? (el.textContent || "").trim() : "";
  }

  function parseApiXml(xmlStr) {
    const doc = new DOMParser().parseFromString(xmlStr, "text/xml");
    const id = xmlText(doc, "id");      // usually "2409.09977"
    const title = xmlText(doc, "title");
    const abstract = xmlText(doc, "abstract");

    const authors = [...doc.getElementsByTagName("author")].map(a => ({
      keyname: xmlText(a, "keyname"),
      forenames: xmlText(a, "forenames")
    }));

    return { id, title, abstract, authors };
  }

  function parseScrapeXml(xmlStr) {
    const doc = new DOMParser().parseFromString(xmlStr, "text/xml");
    const item = doc.getElementsByTagName("item")[0];
    const id = item?.getAttribute("id") || "";

    const v = doc.getElementsByTagName("version")[0];
    let version = "";
    if (v) {
      const number = v.getAttribute("number") || ""; // like [v4]
      const m = /\[v(\d+)\]/i.exec(number);
      if (m) version = "v" + m[1];
    }
    return { id, version };
  }

  function parseHtmlLanding(htmlStr) {
    const doc = new DOMParser().parseFromString(htmlStr, "text/html");
    const bodyText = doc.body?.textContent || "";
    const cite = extractArxivFromHtmlCiteAs(htmlStr);
    const id = cite.id || extractArxivFromText(bodyText).id;
    const version = cite.version || extractArxivFromText(bodyText).version;

    let title = (doc.querySelector('meta[name="citation_title"]')?.getAttribute("content") || "").trim();
    if (!title) title = (doc.title || "").trim();

    // Try to find "Title:" label text on some arXiv HTML copies
    if (!title) {
      const titleLabel = [...doc.querySelectorAll("h1,h2,b,strong,td,div,span,p")]
        .find(el => /title\s*:/i.test(el.textContent));
      if (titleLabel) {
        const m = /title\s*:\s*(.+)$/i.exec(titleLabel.textContent);
        if (m) title = m[1].trim();
      }
    }

    // Abstract from HTML page
    const fullText = bodyText.replace(/\s+/g," ").trim();
    let abstract = "";
    const absHeads = ["abstract","summary","synopsis","summary and conclusions"];
    for (const h of absHeads) {
      const idx = fullText.toLowerCase().indexOf(h);
      if (idx !== -1) {
        const slice = fullText.slice(idx);
        const stop = slice.search(/\b(comments|subjects|cite as|submission history|full-text links)\b/i);
        abstract = (stop > 0 ? slice.slice(0, stop) : slice)
          .replace(new RegExp(`\\b${h}\\b\\s*:?\\s*`,"i"), "")
          .trim();
        break;
      }
    }

    return { id, version, title, abstract, sanitizedHtml: stripScripts(htmlStr), bodyText };
  }

  // ----------------------------
  // Title rules (your logic)
  // ----------------------------
  function cleanTitleForCompare(s) {
    if (!s) return "";
    let t = String(s);

    // Remove "Preprint" (anywhere, case-insensitive)
    t = t.replace(/\bpreprint\b/ig, "").trim();

    // Remove trailing asterisks used as markers
    t = t.replace(/\*+$/g, "").trim();

    // Remove purely formatting $...$ wrappers (keep inside)
    // Example: "$z > 6$" should compare as "z > 6"
    t = t.replace(/\$/g, "");

    // Collapse whitespace only (do NOT normalize punctuation/hyphens)
    t = t.replace(/\s+/g, " ").trim();

    return t;
  }

  function titlesMatchStrict(pdfTitle, htmlTitle) {
    // Hyphen differences should count as mismatch => we do NOT normalize hyphens
    return cleanTitleForCompare(pdfTitle) === cleanTitleForCompare(htmlTitle);
  }

  // Choose title rule:
  // - If not totally different => choose the more complete one
  // - If any mismatch in content => choose HTML
  // Your simplified safe rule: if not EXACT match -> choose HTML
  function chooseTitle(pdfTitle, htmlTitle) {
    const p = cleanTitleForCompare(pdfTitle);
    const h = cleanTitleForCompare(htmlTitle);
    if (!p && h) return htmlTitle;
    if (!h && p) return pdfTitle;
    if (p === h) {
      // choose more complete (longer raw string)
      return (String(pdfTitle).length >= String(htmlTitle).length) ? pdfTitle : htmlTitle;
    }
    // mismatch => HTML
    return htmlTitle || pdfTitle;
  }

  // ----------------------------
  // Keywords extraction (REAL)
  // - Supports: Keywords / Key words / Index Terms / Keywords and Phrases / Subject Headings
  // - Split by common separators; DO NOT split by space
  // - Prefer keywords AFTER Abstract if both exist
  // ----------------------------
  const KW_HEAD_RE = /\b(key\s*words?|keywords?\s*and\s*phrases|index\s*terms|subject\s*headings)\b\s*[:\-–—]?\s*/ig;

  function splitKeywords(raw) {
    if (!raw) return [];
    let s = raw.trim();

    // Stop at common next-section headings
    s = s.split(/\b(abstract|introduction|1\.\s*introduction|background|methods|conclusions)\b/i)[0].trim();

    // Remove leading heading remnants if any
    s = s.replace(/^\s*(key\s*words?|keywords?|index\s*terms|subject\s*headings)\s*[:\-–—]?\s*/i, "");

    // Split by separators (NOT space)
    const parts = s.split(/[;•,\u2022|·\u00b7\/]+/).map(x => x.trim()).filter(Boolean);

    // Also handle dashed separators used between terms, BUT keep hyphenated words
    // We only split on " - " or " – " patterns with surrounding spaces
    const expanded = [];
    for (const p of parts) {
      const sub = p.split(/\s[–—-]\s/g).map(x => x.trim()).filter(Boolean);
      expanded.push(...sub);
    }
    return expanded.filter(Boolean);
  }

  function extractKeywordsFromTextBlock(text) {
    if (!text) return [];

    // Find all occurrences of headings
    const matches = [];
    let m;
    KW_HEAD_RE.lastIndex = 0;
    while ((m = KW_HEAD_RE.exec(text)) !== null) {
      matches.push({ idx: m.index, head: m[0] });
    }
    if (!matches.length) return [];

    // Prefer the occurrence AFTER abstract if abstract exists
    const absIdx = text.toLowerCase().indexOf("abstract");
    let pick = matches[matches.length - 1];
    if (absIdx !== -1) {
      const afterAbs = matches.filter(x => x.idx > absIdx);
      if (afterAbs.length) pick = afterAbs[afterAbs.length - 1];
    }

    const slice = text.slice(pick.idx);
    // Take a limited window to avoid capturing half the paper
    const window = slice.slice(0, 800);

    // Remove the heading and capture rest of line / paragraph start
    const afterHead = window.replace(KW_HEAD_RE, "").trim();

    // Keywords often end at newline-ish; PDF text might be single-line, so also stop at double spaces before next section
    const stopAt = afterHead.search(/\b(abstract|introduction|1\.\s*introduction|classification|pacs|msc|jel)\b/i);
    const raw = (stopAt > 0 ? afterHead.slice(0, stopAt) : afterHead).trim();

    return splitKeywords(raw);
  }

  // ----------------------------
  // Abstract extraction (prefer API, else PDF/HTML)
  // and preserve unicode super/sub into tags (best effort)
  // ----------------------------
  const SUP_MAP = {
    "⁰":"0","¹":"1","²":"2","³":"3","⁴":"4","⁵":"5","⁶":"6","⁷":"7","⁸":"8","⁹":"9","⁻":"-","⁺":"+"
  };
  const SUB_MAP = {
    "₀":"0","₁":"1","₂":"2","₃":"3","₄":"4","₅":"5","₆":"6","₇":"7","₈":"8","₉":"9","₋":"-","₊":"+"
  };

  function escapeXml(s){
    return String(s||"").replace(/[<>&'"]/g, c => ({'<':'&lt;','>':'&gt;','&':'&amp;',"'":'&apos;','"':'&quot;'}[c]));
  }

  // Converts unicode superscripts/subscripts into <sup> / <inf> sequences
  function encodeSuperSubToXml(text) {
    if (!text) return "";
    let out = "";
    let i = 0;

    function readRun(map) {
      let run = "";
      while (i < text.length && map[text[i]]) {
        run += map[text[i]];
        i++;
      }
      return run;
    }

    while (i < text.length) {
      const ch = text[i];
      if (SUP_MAP[ch]) {
        const run = readRun(SUP_MAP);
        out += `<sup>${escapeXml(run)}</sup>`;
        continue;
      }
      if (SUB_MAP[ch]) {
        const run = readRun(SUB_MAP);
        // Elsevier example shows <inf> for subscript letters; for digits we'll still use <inf>
        out += `<inf>${escapeXml(run)}</inf>`;
        continue;
      }
      out += escapeXml(ch);
      i++;
    }
    return out;
  }

  function extractAbstractFromPdfText(pdfText) {
    if (!pdfText) return "";
    const t = pdfText.replace(/\s+/g, " ").trim();
    const heads = ["abstract", "summary", "synopsis", "summary and conclusions"];
    for (const h of heads) {
      const idx = t.toLowerCase().indexOf(h);
      if (idx !== -1) {
        const slice = t.slice(idx);
        const stop = slice.search(/\b(key\s*words?|keywords?|index\s*terms|subject\s*headings|introduction|1\.\s*introduction|contents)\b/i);
        const body = (stop > 0 ? slice.slice(0, stop) : slice)
          .replace(new RegExp(`\\b${h}\\b\\s*:?\\s*`,"i"), "")
          .trim();
        return body;
      }
    }
    return "";
  }

  // ----------------------------
  // References extraction from PDF (best effort)
  // ----------------------------
  function extractReferencesFromPdfText(pdfText) {
    if (!pdfText) return [];
    const t = pdfText.replace(/\r/g, "\n");
    const lowerT = t.toLowerCase();

    let start = -1;
    const heads = ["references", "bibliography"];
    for (const h of heads) {
      const idx = lowerT.lastIndexOf("\n" + h);
      if (idx !== -1) { start = idx; break; }
    }
    if (start === -1) {
      const idx2 = lowerT.lastIndexOf(hadsafe("\nreferences"));
      if (idx2 !== -1) start = idx2;
    }
    if (start === -1) return [];

    let tail = t.slice(start);
    tail = tail.replace(/^\s*(references|bibliography)\s*/i, "").trim();

    // Try split by common numbering patterns
    // [1] ...  OR  1. ...  OR  1 ... (at line starts)
    const lines = tail.split("\n").map(x => x.trim()).filter(Boolean);

    const refs = [];
    let cur = "";

    function pushCur() {
      const r = cur.trim();
      if (r) refs.push(r);
      cur = "";
    }

    const startsNew = (line) =>
      /^\[\s*\d+\s*\]/.test(line) ||
      /^(\d+)\.\s+/.test(line) ||
      /^(\d+)\s+/.test(line);

    for (const line of lines) {
      if (startsNew(line)) {
        pushCur();
        cur = line.replace(/^\[\s*\d+\s*\]\s*/, "").replace(/^(\d+)\.\s+/, "").replace(/^(\d+)\s+/, "");
      } else {
        cur += (cur ? " " : "") + line;
      }
      if (refs.length >= 300) break;
    }
    pushCur();

    // Clean duplicates / too short
    return refs.map(r => r.replace(/\s+/g, " ").trim()).filter(r => r.length > 10);
  }

  function hadsafe(s){ return s; } // placeholder, keeps code safe

  // ----------------------------
  // Affiliations extraction from PDF first page (best effort)
  // ----------------------------
  function extractAffiliationsFromFirstPageText(pageText) {
    if (!pageText) return [];
    const lines = pageText.split("\n").map(l => l.trim()).filter(Boolean);

    const aff = [];
    const looksAff = (l) =>
      /university|universit|institute|institut|department|dept\.|laboratory|centre|center|school|faculty|cnrs|infn|inaf|observator|hospital|clinic|research/i.test(l);

    for (const l of lines) {
      if (looksAff(l) && l.length >= 12) aff.push(l);
    }

    // De-dup
    const uniq = [];
    const seen = new Set();
    for (const a of aff) {
      const k = a.toLowerCase();
      if (!seen.has(k)) { seen.add(k); uniq.push(a); }
    }
    return uniq.slice(0, 12);
  }

  // ORCID extraction (best effort)
  function extractOrcids(text) {
    const out = [];
    const re = /\b(\d{4}-\d{4}-\d{4}-\d{3}[\dX])\b/g;
    let m;
    while ((m = re.exec(text)) !== null) out.push(m[1]);
    return [...new Set(out)];
  }

  // ----------------------------
  // Build strict Elsevier XML (structure matches your sample)
  // ----------------------------
  function buildElsevierXmlStrict({ arxivIdWithVersion, chosenTitle, abstractText, keywords, authors, affiliations, references }) {
    const nowIso = new Date().toISOString();

    const kwXml = (keywords?.length)
      ? `            <author-keywords>
${keywords.map(k => `              <author-keyword>${escapeXml(k)}</author-keyword>`).join("\n")}
            </author-keywords>\n`
      : "";

    // Author-groups: one per author (seq increments), attach best-effort affiliation
    const affText = affiliations?.[0] || "";
    const authorsXml = (authors || []).map((a, i) => {
      const given = a.forenames || "";
      const surname = a.keyname || "";
      const initials = given
        .split(/\s+/).filter(Boolean)
        .map(x => x[0].toUpperCase() + ".")
        .join("");

      // If we have multiple affiliation candidates, rotate them (better than always same)
      const affPick = (affiliations && affiliations.length) ? affiliations[Math.min(i, affiliations.length - 1)] : "";

      const affXml = affPick ? `
          <affiliation>
            <!-- telemetry: {"confidence": 0.25} -->
            <ce:source-text>${escapeXml(affPick)}</ce:source-text>
          </affiliation>` : "";

      return `          <author-group seq="${i+1}">
            <author seq="${i+1}">
              <ce:initials>${escapeXml(initials || "")}</ce:initials>
              <ce:surname>${escapeXml(surname)}</ce:surname>
              <ce:given-name>${escapeXml(given)}</ce:given-name>
            </author>${affXml}
          </author-group>`;
    }).join("\n");

    const absXml = abstractText
      ? `          <abstracts>
            <abstract original="y" xml:lang="ENG">
              <ce:para>${encodeSuperSubToXml(abstractText)}</ce:para>
            </abstract>
          </abstracts>\n`
      : "";

    const refs = references || [];
    const bibXml = refs.length
      ? `          <bibliography refcount="${refs.length}">
${refs.map((r, i) => `            <reference seq="${i+1}">
              <ref-info/>
              <ref-fulltext>${escapeXml(r)}</ref-fulltext>
              <ce:source-text>${escapeXml(r)}</ce:source-text>
            </reference>`).join("\n")}
          </bibliography>`
      : `          <bibliography refcount="0"/>`;

    return `<?xml version="1.0" encoding="utf-8"?>
<units xmlns="http://www.elsevier.com/xml/ani/ani" xmlns:ce="http://www.elsevier.com/xml/ani/common">
  <unit type="ARTICLE">
    <unit-info>
      <unit-id>1</unit-id>
      <order-id>unknown</order-id>
      <parcel-id>none</parcel-id>
      <supplier-id>4</supplier-id>
      <timestamp>${escapeXml(nowIso)}</timestamp>
    </unit-info>
    <unit-content>
      <bibrecord>
        <item-info>
          <status state="new"/>
          <itemidlist>
            <itemid idtype="ARXIV">${escapeXml(arxivIdWithVersion)}</itemid>
          </itemidlist>
        </item-info>
        <head>
          <citation-info>
            <citation-type code="ar"/>
            <citation-language xml:lang="ENG"/>
            <abstract-language xml:lang="ENG"/>
${kwXml}          </citation-info>
          <citation-title>
            <titletext xml:lang="ENG" original="y">${escapeXml(chosenTitle)}</titletext>
          </citation-title>
${authorsXml || "          <!-- No authors parsed -->"}
${absXml}          <source srcid="???"/>
        </head>
        <tail>
${bibXml}
        </tail>
      </bibrecord>
    </unit-content>
  </unit>
</units>`;
  }

  // ----------------------------
  // Robust support-doc detection (BY CONTENT)
  // ----------------------------
  async function detectSupportDocsByContent(zip, guessedId) {
    const names = Object.keys(zip.files).filter(n => !zip.files[n].dir);

    const xmlNames = names.filter(n => lower(n).endsWith(".xml"));
    const htmlNames = names.filter(n => lower(n).endsWith(".html") || lower(n).endsWith(".htm"));

    let apiName = null;
    let scrapeName = null;
    let finalName = null;

    for (const n of xmlNames) {
      const txt = await zip.file(n).async("string");
      const head = txt.slice(0, 9000).toLowerCase();

      const looksFinal = head.includes("<units") && head.includes("elsevier.com/xml/ani");
      if (!finalName && looksFinal) finalName = n;

      const looksApi =
        head.includes("<record") ||
        head.includes("oai:arxiv.org:") ||
        head.includes("<arxiv") ||
        head.includes("<metadata");

      const looksScrape =
        head.includes("<item") && head.includes("version") && head.includes("[v");

      if (!apiName && looksApi && !looksFinal) apiName = n;
      if (!scrapeName && looksScrape && !looksFinal) scrapeName = n;
    }

    // Prefer filename match if guessedId exists
    if (guessedId) {
      const apiByName = xmlNames.find(n => n.includes(guessedId) && n !== scrapeName && n !== finalName);
      if (apiByName) apiName = apiByName;

      const scrapeByName = xmlNames.find(n => n.includes(guessedId) && n !== apiName && n !== finalName);
      if (scrapeByName) scrapeName = scrapeByName;

      const finalByName = xmlNames.find(n => n.includes(guessedId) && n !== apiName && n !== scrapeName);
      if (finalByName) {
        const txt = await zip.file(finalByName).async("string");
        if (txt.toLowerCase().includes("<units") && txt.toLowerCase().includes("elsevier.com/xml/ani")) finalName = finalByName;
      }
    }

    const htmlName = (guessedId
      ? (htmlNames.find(n => n.includes(guessedId)) || htmlNames[0] || null)
      : (htmlNames[0] || null)
    );

    return { apiName, scrapeName, htmlName, finalName };
  }

  // ----------------------------
  // ZIP Load
  // ----------------------------
  zipInput.addEventListener("change", async (e) => {
    const file = e.target.files?.[0];
    if (!file) return;

    resetAll();
    zipBadge.className = "badge warn";
    zipBadge.textContent = "Loading ZIP…";

    try {
      const buf = await file.arrayBuffer();
      const zip = await JSZip.loadAsync(buf);
      state.zip = zip;

      state.fileNames = Object.keys(zip.files).filter(n => !zip.files[n].dir);
      state.pdfs = state.fileNames.filter(n => lower(n).endsWith(".pdf"));

      fileCount.textContent = String(state.pdfs.length);
      zipBadge.className = "badge good";
      zipBadge.textContent = `ZIP loaded: ${file.name}`;

      renderPdfList();
      if (state.pdfs.length) selectPdf(0);

    } catch (err) {
      console.error(err);
      zipBadge.className = "badge bad";
      zipBadge.textContent = "Failed to read ZIP";
    }
  });

  function resetAll(){
    state.fileNames = [];
    state.pdfs = [];
    state.selectedPdf = null;
    state.selected = { pdfName:null, apiName:null, scrapeName:null, htmlName:null, finalName:null };
    state.pdfTextByPage = [];
    state.pdfAllText = "";

    apiText.value = "";
    scrapeText.value = "";
    htmlPreview.innerHTML = "No HTML loaded.";
    outXml.value = "";

    downloadBtn.disabled = true;
    runBtn.disabled = true;

    pdfIdVal.textContent = "—";
    htmlIdVal.textContent = "—";
    scrapeIdVal.textContent = "—";
    pdfVerVal.textContent = "—";
    htmlVerVal.textContent = "—";
    scrapeVerVal.textContent = "—";
    pdfTitleVal.textContent = "—";
    htmlTitleVal.textContent = "—";

    matchVal.innerHTML = "—";
    titleVal.textContent = "—";
    absVal.innerHTML = "—";
    kwVal.innerHTML = "—";
    authVal.innerHTML = "—";
    affVal.innerHTML = "—";
    refVal.innerHTML = "—";

    selectedSet.textContent = "No set selected";

    clearPdf();
    fileList.innerHTML = "";
    fileCount.textContent = "0";
  }

  // ----------------------------
  // Render PDF list
  // ----------------------------
  function renderPdfList(){
    fileList.innerHTML = "";
    state.pdfs.forEach((pdfName, idx) => {
      const div = document.createElement("div");
      div.className = "item" + (idx === state.selectedPdf ? " active" : "");
      const idGuess = extractArxivFromText(pdfName).id || "PDF";
      div.innerHTML = `
        <div style="display:flex;align-items:center;justify-content:space-between;gap:8px">
          <div style="font-weight:900;font-size:13px">${escapeHtml(pdfName.split("/").pop())}</div>
          <span class="badge">${escapeHtml(idGuess)}</span>
        </div>
        <div class="muted" style="margin-top:6px">Auto-detects API/Scrape/HTML by file content.</div>
      `;
      div.addEventListener("click", () => selectPdf(idx));
      fileList.appendChild(div);
    });
  }

  async function selectPdf(idx){
    state.selectedPdf = idx;
    renderPdfList();

    const pdfName = state.pdfs[idx];
    selectedSet.textContent = `Selected: ${pdfName.split("/").pop()}`;

    const { id: guessedId } = extractArxivFromText(pdfName);
    const support = await detectSupportDocsByContent(state.zip, guessedId);

    state.selected = {
      pdfName,
      apiName: support.apiName,
      scrapeName: support.scrapeName,
      htmlName: support.htmlName,
      finalName: support.finalName
    };

    runBtn.disabled = false;

    await loadPdfFromZip(pdfName);
    await loadTextPreview(state.selected.apiName, apiText);
    await loadTextPreview(state.selected.scrapeName, scrapeText);
    await loadHtmlPreview(state.selected.htmlName);
  }

  async function loadTextPreview(name, targetTextarea){
    if (!name) { targetTextarea.value = ""; return; }
    const file = state.zip.file(name);
    if (!file) { targetTextarea.value = ""; return; }
    targetTextarea.value = await file.async("string");
  }

  async function loadHtmlPreview(name){
    if (!name) { htmlPreview.innerHTML = "No HTML loaded."; return; }
    const file = state.zip.file(name);
    if (!file) { htmlPreview.innerHTML = "No HTML loaded."; return; }
    const txt = await file.async("string");
    htmlPreview.innerHTML = stripScripts(txt) || "No HTML content.";
  }

  // ----------------------------
  // PDF preview + text extraction
  // ----------------------------
  function clearPdf(){
    state.pdfDoc = null;
    state.pdfPageNum = 1;
    state.pdfPageCount = 0;
    pageInfo.textContent = "- / -";
    prevPageBtn.disabled = true;
    nextPageBtn.disabled = true;
    const ctx = pdfCanvas.getContext("2d");
    ctx.clearRect(0,0,pdfCanvas.width,pdfCanvas.height);
  }

  async function loadPdfFromZip(name){
    clearPdf();
    state.pdfTextByPage = [];
    state.pdfAllText = "";

    const file = state.zip.file(name);
    if (!file) return;

    const u8 = await file.async("uint8array");
    const loadingTask = pdfjsLib.getDocument({ data: u8 });
    const pdf = await loadingTask.promise;

    state.pdfDoc = pdf;
    state.pdfPageCount = pdf.numPages;
    state.pdfPageNum = 1;

    // Extract text (all pages) for rules, keywords, refs
    const texts = [];
    for (let p = 1; p <= pdf.numPages; p++) {
      const page = await pdf.getPage(p);
      const tc = await page.getTextContent();
      const pageText = tc.items.map(it => it.str).join(" ");
      texts.push(pageText);
    }
    state.pdfTextByPage = texts;
    state.pdfAllText = texts.join("\n");

    await renderPdfPage(1);
  }

  async function renderPdfPage(num){
    if (!state.pdfDoc) return;
    const page = await state.pdfDoc.getPage(num);
    const viewport = page.getViewport({ scale: 1.3 });
    const ctx = pdfCanvas.getContext("2d");
    pdfCanvas.width = viewport.width;
    pdfCanvas.height = viewport.height;

    await page.render({ canvasContext: ctx, viewport }).promise;

    pageInfo.textContent = `${num} / ${state.pdfPageCount}`;
    prevPageBtn.disabled = (num <= 1);
    nextPageBtn.disabled = (num >= state.pdfPageCount);
  }

  prevPageBtn.addEventListener("click", async () => {
    if (!state.pdfDoc || state.pdfPageNum <= 1) return;
    state.pdfPageNum -= 1;
    await renderPdfPage(state.pdfPageNum);
  });

  nextPageBtn.addEventListener("click", async () => {
    if (!state.pdfDoc || state.pdfPageNum >= state.pdfPageCount) return;
    state.pdfPageNum += 1;
    await renderPdfPage(state.pdfPageNum);
  });

  // ----------------------------
  // VALIDATION LOGIC (your rules)
  // ----------------------------
  function normalizeVersion(v){
    if (!v) return "";
    const m = /v(\d+)/i.exec(String(v).trim());
    return m ? ("v" + m[1]) : "";
  }

  function normalizeId(id){
    return (id || "").trim();
  }

  // Process rules:
  // A) If PDF has arXiv ID:
  //    - IDs must match across PDF/HTML/Scrape (where present)
  //    - Versions:
  //        - If PDF has version => all three versions must match
  //        - If PDF has NO version => HTML and Scrape versions must match (and exist)
  //
  // B) If PDF has NO arXiv ID:
  //    - PDF title must match HTML title (strict compare after formatting-clean)
  //    - Then HTML and Scrape ID+versions must match
  //
  function decideProcess({
    pdfId, pdfVer,
    htmlId, htmlVer,
    scrapeId, scrapeVer,
    pdfTitle, htmlTitle
  }) {
    const pid = normalizeId(pdfId);
    const hid = normalizeId(htmlId);
    const sid = normalizeId(scrapeId);

    const pv = normalizeVersion(pdfVer);
    const hv = normalizeVersion(htmlVer);
    const sv = normalizeVersion(scrapeVer);

    const hasPdfId = !!pid;

    // Helper: ensure id equality for those present
    const allIds = [pid, hid, sid].filter(Boolean);
    const idsAllSame = allIds.length ? allIds.every(x => x === allIds[0]) : false;

    // Helper: versions logic
    const htmlScrapeHave = !!hv && !!sv;
    const htmlScrapeSame = htmlScrapeHave && hv === sv;

    if (hasPdfId) {
      if (!idsAllSame) return { ok:false, reason:"ID mismatch across support docs" };

      // If PDF version exists -> must match all present (and require html+scrape exist)
      if (pv) {
        if (!hv || !sv) return { ok:false, reason:"PDF has version but HTML/Scrape missing version" };
        if (!(pv === hv && pv === sv)) return { ok:false, reason:"Version mismatch (PDF vs HTML vs Scrape)" };
        return { ok:true, reason:"OK: IDs match, versions match (PDF+HTML+Scrape)" };
      }

      // PDF has no version -> HTML and Scrape versions must match
      if (!htmlScrapeSame) return { ok:false, reason:"PDF has no version; HTML/Scrape versions must exist and match" };
      return { ok:true, reason:"OK: IDs match; PDF no version; HTML+Scrape versions match" };
    }

    // PDF has NO ID -> title must match first
    if (!titlesMatchStrict(pdfTitle, htmlTitle)) {
      return { ok:false, reason:"PDF has no ID; Title mismatch (PDF vs HTML) => HOLD" };
    }

    // Then HTML+Scrape ID+version must match
    if (!hid || !sid) return { ok:false, reason:"PDF has no ID; HTML or Scrape missing ID" };
    if (hid !== sid) return { ok:false, reason:"PDF has no ID; HTML vs Scrape ID mismatch" };

    if (!htmlScrapeSame) return { ok:false, reason:"PDF has no ID; HTML/Scrape versions must exist and match" };

    return { ok:true, reason:"OK: PDF no ID; titles match; HTML+Scrape ID+versions match" };
  }

  // ----------------------------
  // Run Extraction
  // ----------------------------
  runBtn.addEventListener("click", async () => {
    try {
      if (!state.selected?.pdfName) return;

      const apiRaw = apiText.value || "";
      const scrapeRaw = scrapeText.value || "";
      const htmlRaw = state.selected.htmlName ? await state.zip.file(state.selected.htmlName).async("string") : "";
      const finalRaw = state.selected.finalName ? await state.zip.file(state.selected.finalName).async("string") : "";

      const api = apiRaw ? parseApiXml(apiRaw) : null;
      const scrape = scrapeRaw ? parseScrapeXml(scrapeRaw) : null;
      const html = htmlRaw ? parseHtmlLanding(htmlRaw) : null;

      // Extract from PDF text: ID/version + title + keywords + abstract + refs + affiliations
      const pdfAll = state.pdfAllText || "";
      const pdfFirst = state.pdfTextByPage?.[0] || pdfAll;

      const pdfArxiv = extractArxivFromText(pdfAll);
      const pdfId = pdfArxiv.id || "";
      const pdfVer = pdfArxiv.version || "";

      // HTML cite-as second line
      const htmlId = html?.id || "";
      const htmlVer = html?.version || "";

      const scrapeId = scrape?.id || "";
      const scrapeVer = scrape?.version || "";

      // Titles: PDF title is hard to perfectly extract without layout; we approximate:
      // Use API title as "PDF-side title" fallback if PDF title extraction fails.
      // If you later add manual tagging, replace this.
      const pdfTitleApprox = api?.title || ""; // safer fallback
      const htmlTitle = html?.title || "";

      // Show values in UI
      pdfIdVal.textContent = pdfId || "—";
      htmlIdVal.textContent = htmlId || "—";
      scrapeIdVal.textContent = scrapeId || "—";
      pdfVerVal.textContent = normalizeVersion(pdfVer) || "—";
      htmlVerVal.textContent = normalizeVersion(htmlVer) || "—";
      scrapeVerVal.textContent = normalizeVersion(scrapeVer) || "—";

      pdfTitleVal.textContent = pdfTitleApprox ? pdfTitleApprox : "—";
      htmlTitleVal.textContent = htmlTitle ? htmlTitle : "—";

      // Decide process/hold
      const decision = decideProcess({
        pdfId, pdfVer,
        htmlId, htmlVer,
        scrapeId, scrapeVer,
        pdfTitle: pdfTitleApprox,
        htmlTitle
      });

      matchVal.innerHTML = decision.ok ? badge("PROCESS ✅ " + decision.reason, "good") : badge("HOLD ⛔ " + decision.reason, "bad");

      // If HOLD, do not generate XML (per your rule)
      if (!decision.ok) {
        outXml.value = "";
        downloadBtn.disabled = true;
        titleVal.textContent = "—";
        absVal.innerHTML = badge("—", "warn");
        kwVal.innerHTML = badge("—", "warn");
        authVal.innerHTML = badge("—", "warn");
        affVal.innerHTML = badge("—", "warn");
        refVal.innerHTML = badge("—", "warn");
        return;
      }

      // Choose ID + version output
      const finalId = normalizeId(htmlId || scrapeId || api?.id || pdfId);
      const finalV = normalizeVersion(htmlVer || scrapeVer || pdfVer);

      const arxivIdWithVersion = (finalId && finalV) ? `${finalId}${finalV}` : (finalId || "");

      // Choose title (your rule)
      const chosenTitle = chooseTitle(pdfTitleApprox, htmlTitle).trim();

      // Keywords: prefer PDF, fallback to HTML
      const kwPdf = extractKeywordsFromTextBlock(pdfAll);
      const kwHtml = extractKeywordsFromTextBlock((html?.bodyText || ""));
      const keywords = (kwPdf.length ? kwPdf : kwHtml);

      // Abstract: prefer API (most stable), else PDF, else HTML
      const absFromApi = (api?.abstract || "").trim();
      const absFromPdf = extractAbstractFromPdfText(pdfAll);
      const absFromHtml = (html?.abstract || "").trim();
      const abstractText = (absFromApi || absFromPdf || absFromHtml).trim();

      // Authors: from API (stable)
      const authors = api?.authors || [];

      // Affiliations: best-effort from PDF first page
      const affiliations = extractAffiliationsFromFirstPageText(pdfFirst);

      // References: best-effort from PDF
      const references = extractReferencesFromPdfText(pdfAll);

      // UI status flags
      titleVal.textContent = chosenTitle || "—";
      absVal.innerHTML = abstractText ? badge("Yes", "good") : badge("No", "warn");
      kwVal.innerHTML = keywords.length ? badge(`${keywords.length} keyword(s)`, "good") : badge("None detected", "warn");
      authVal.innerHTML = authors.length ? badge(`API authors: ${authors.length}`, "good") : badge("No authors parsed", "warn");
      affVal.innerHTML = affiliations.length ? badge(`${affiliations.length} affiliation line(s)`, "good") : badge("None detected", "warn");
      refVal.innerHTML = references.length ? badge(`${references.length} reference(s)`, "good") : badge("None detected", "warn");

      // If ZIP already contains final Elsevier XML, we can optionally output it as-is.
      // But your request is to GENERATE. We'll still generate.
      const xml = buildElsevierXmlStrict({
        arxivIdWithVersion,
        chosenTitle,
        abstractText,
        keywords,
        authors,
        affiliations,
        references
      });

      outXml.value = xml;
      downloadBtn.disabled = !xml;

    } catch (e) {
      console.error(e);
      alert("Extraction failed. Open DevTools Console and send me the red error line.");
    }
  });

  downloadBtn.addEventListener("click", () => {
    const xml = outXml.value;
    if (!xml) return;
    const blob = new Blob([xml], { type: "application/xml;charset=utf-8" });
    const a = document.createElement("a");
    a.href = URL.createObjectURL(blob);
    a.download = `ACE_${Date.now()}_arxiv.xml`;
    document.body.appendChild(a);
    a.click();
    a.remove();
  });
</script>
</body>
</html>
